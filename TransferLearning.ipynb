{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import cv2\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications import MobileNet, MobileNetV2\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from pathlib import Path\n",
    "import os\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import GaussianNoise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Load training data from npz array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1500, 784), (1500,))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = np.load('train.npz')\n",
    "train_x = train_ds['arr_0']\n",
    "train_y = train_ds['arr_1']\n",
    "\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194\n",
      "195\n",
      "197\n",
      "198\n",
      "203\n",
      "208\n",
      "215\n",
      "223\n",
      "233\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU4AAAD7CAYAAAAFI30bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO2dd4AURdbAf7WzCVgyLCBxgSWqoCCCkTtEARMmFCPqyZkxfnreGc5wegbEwIGY0DMLnjmBWUEkGJCcJSw5LXFTfX+8nu5ZNjY7MzszvN8/01NV3V0zb7rmvar3XhlrLYqiKErlSaruDiiKosQbOnAqiqL4RAdORVEUn+jAqSiK4hMdOBVFUXyiA6eiKIpPqjRwGmMGGGMWGGMWG2NuD1enlOpF5Zq4qGzDg9lfP05jTABYCPQHVgHTgaHW2rnh654SbVSuiYvKNnwkV+HcXsBia+1SAGPMG8DpQJlCSDVpNp1aVbhlfJPLlo3W2sbV3Y8KULn6JE7kCj5lW+1yNfKSdcgOt2jBpiYApK7eWeHpe1tK3zvXX+eWLZ2dIQeV0BfLk2tVBs7mwMqQ96uAI8s7IZ1aHGn6VeGW8c1kO2FFdfehEqhcfRIncgWfsq1uuZpkGZ5e/vgbt+yYV24EIOtvUys8f9Ft8tE+HzzSLbsw63gAbEFBheeXJ9eqDJyVwhgzHBgOkE7NSN9OiRIq18QkluQaHNyGLhjqlo0ZMg6AR/95BABFe/aUOC+ppvT7vhMnAPCXpWeGXHNdifb7Q1UWh1YDLUPet3DKimGtHWet7Wmt7ZlCWhVup0QJlWviUqFsVa6VoyoD53Qg2xiTZYxJBc4D3g9Pt5RqROWauKhsw8R+m+rW2gJjzLXAZ0AAeMFaOydsPVOqBZVr4hKvss0b3cw97je6EICbrzgcgCZPTSnRfunfuwFwQW2pe+a21m5dDcJjqldpjtNa+zHwcVh6osQMKtfERWUbHiK+OKQoyoHNwDlb3ePhdRcC0GPq5QC0Omd2hefX/N809/if93QB4PS/yEr7j0+llGhvg25MH10BQId3f9qPXpePhlwqiqL4RDVORVEiyueDD3ePn7hD/ELv7vMBAI+POBuApk+UnKssjf893xeAX27/DwDZD18FQNv/8/w62941Haicr+b+ohqnoiiKT2JO40yqXRuABfd3dctqtswFoPUtEmZlU7xuFy5YHMXeVUxSejpQ/N8ukv98ihLrFC5a6h53uFReXxpwOgC7L3FCJ5+o3LWaPCWaZZ+BZwGw6MIxAOw6P89t83OejA8P9Bkg91+3fv86Xg6qcSqKovhEB05FURSfxIypnndSTwBStucDMGrQy27dmvz6AHzAEdHvWAWYHjKlsOCvEh87beAoAI6dcpXbps25v0W/Y4oSw6T/MB+AlMMP8XXe1gt7A/DtoU8CsCx/LwD9v7/ObTOv73MALLmuHQBt/qGmuqIoSrUTMxpn6mczir0fO2iAe+xNLi+PXofKYeHYXu7xstMkW8uOIsnS8tw20UBbP6n/SYqyL8HF34LD2wNQ+48iX+dv6iaJNJMcne+abicD0G7rz26bV+dLiGZy5+1V62w56NOtKIrik5jROPcl1IUhVtg7UOZYF546xi3r8M1lALS/W7JULz9XMlSf+KQX5hVw/p8me37AinLAkNy2jXu8vZs8H+mbxX2o7is/+rpW6lZ5lpKc9PB7Hc11d6YXenlRbXGOv39pnf3rcCVQjVNRFMUnOnAqiqL4pEJT3RjzAnAKsN5ae7BT1gB4E2iDrNgMsdZuCWvPkgLu4fbzxETOyxD1vPZqLxKnxrfi1lCUmxvW25fGMQ+KWfF6bhO3LPuWDQDUfWs3AHOzJgJw7WpvK5fv1raNeN/8Um1yDSPmCHFlSVq2BoDCjZuqszsxQ6zJtmDpcve4ZshxWSQd2gmAtcc1ACA/ZL+4wjRZHJrvuCE996KEHG0r8kz1O9fLeJF9pywY+Vt+qhyV0TjHAwP2Kbsd+MJamw184bxX4ovxqFwTlfGobCNKhRqntfZbY0ybfYpPB/o6xy8BXwO3haNDgcayG+cRk9e4Zf9sPLbM9nPyRNM75atrAehyn2gdBZX4Z6t0n9pnAXB/5v8A6PTs1W7d4W/NA2Bc608A6Hmn7MLX8HkvW0sjFoatL+EiEnIt7Outfq05RmL2G/8i1kEtxzIg4FkShVv8KzxJ3Tq7x5+891/AcwU7+rGb3LqmjxfPthMMsNh8lbetbH6B9GXvStky9s6B77h1q/JE25l6WgcACpb/4buv1UW0n1nwNkgDoH2rYnUmv9DrW4p854W1ZD+jDYeLOtn9Ii8v53MtXwMgYMrW63YVyXVqJtUA4LZ13d262ReIzIr2RO65299V9SbW2hzneC3QpKyGsbRrnlIhKtfEpVKyVblWjiq7I1lrrTGmzO3drbXjgHEAdUyDCreBXzksG4CPG09yyw6/V8IXM2fIPGZu2wy3btPZokFM6SdzHZv/JP9E54+62W1TZ4X8463rVc7MhJM1uv0jC+RtaqpbteCf9QDIKRCXo2MH/OrWPdH8KwCOu7ukphnP+JFrervmdsW/D2H+MS+Ueb2gVphmvLmo57eJZvLvb8WJucs93jbWBWtlb5hVfzsKgN0HiQxTtnsyPPjHCwC4KFtcv2bc8pRb1xMJwUvZIR/hh3skRG/qHm/nxp1WZHzyUdK3/vNOdesmdZZ8kT37/wmAhs/Gj8ZZEeXJtrLPq0mT73HF7T0AGHOxZxX2rVF2bs3OY8VaO+OM7wH4VxMJRx652VsH6PqcWI9tPhAH9sCqDV7/6siz/9DnrwIwP68uAL/29uRq90bewtvfVfV1xphmAM5r+INBlepA5Zq4qGzDyP5qnO8DlwAPOa/vhatDhekly2qtk3UxO+N3ADJCojMz3pLXy7vKHibpYzYDMOvWp9025c2V7MspvQcC0Dh9h1v2dotnAEgzYro82/KHkDNEa6l9njMn+3ylbxWL7JdcD87YxE/H/JesD65wyzo/KnPN2w7LBGB9D1HpA3uM26b50asAmHWyJEa5u+fxbt2MRyWZw5zrxJl5Y6FYFo0CIUusDlkfyn0/zerine9onz/nyW/nxjXHArC8n2dJFG4XjWZ0B0kGkbx6rXfRRfKS60zXNSz9o8cTYXlmA9miGbZ5TX7vnzYX+ZyycKDb5sa3ZE1gW2/R5Jee4Fki866U9m/kSuKetm9fCUD2CM8RvjWisQbV3dBstnndZFv4BklS+tY6WUG3ezfuz8fZbyocUYwxrwNTgY7GmFXGmMuRL7+/MWYRcILzXokjVK6Ji8o28lRmVX1oGVX9wtwXJYqoXBMXlW3kiblY9TZPzQFg7NDmbtmokWJ2XVPregDq/7a15IkrZTFh7yUSn5rzzS636qIFsoiQdoqYYnbv3hKnnzFXJqA/7PBJibqxW8X0+F9XMTuTmx/k1v3xlExOj+4mLhQP0J0DlS7357jHBSvFDM9wcg4Ep1RKY9BQcSOa9Mgot2zGAzMBeGuHfL8vHiqmuy303JkDDcXc67B+FgCFx3Vz61Jek0XCXmnyesUr4irVdHvJhYvChUvketklAxXSN5sSZQcayU29BfhLPvoCgENSRda97pBF2PrjvUXRTKQuU6xyBnY/361bcKk8n0vPkcWk+51tcUIDXiiShcCAM4Wy6LJMt+qRs8QFrUWyLBL98oeY7u2IMVNdURRFKU7MaZyFW7cBkGI8p9mWyZIV/seHy3aEP22RBEqs+a9og8F/JIDke8WZ2e4Vd5f8E3u6dfeMlWzR6SbfuY64pDRO8xaHRjSdDMBj/z4NgJCu0bupaMhNA55j9YHKhn4t3eP641dV+rw6r8vCQPceN7hli88XWZ+3TNxdivZsLnFe0GUpyMqrvGWEbUUSGJFhxE1lT6MKPeGYd1sD97jQimbbcE5eWc0PGHLG1XOP/1xDFoWGni8uQ/W/q9j9ruiXue5x9gh57ZgrLoYLLpNMYz0v9XZM2NpPZDfveFlpDWZCAjhnyUkANG7xGQDdW60EIPIB18VRjVNRFMUnMadxJh0sAf6X1/3FLTtk5K0A1F4lWsBHj4x066bvlTmwHfc5c6KtS15z3c3iFnHko+LKsrvQ21L4OMf96dXcpgDk3SSOJ8vreXOsox8UFTO4FWkoe61oqp0nyfxrNjPL/4AJSE5BOvdv7MS1t7/tlr0xRVyLgvOHlaHl5BBV3pkWu7rZlwD8u+1goHgobXJr0XCz35E5tc+aeftUtXtDAhKO7iPazt/Pkb698dKxbhubI66MS/92KADLBnnyzXpP3GQ6fO7lVT3gMAaTkspXh493iw7/WjTN9t/9XMZJlaPFV44mL+ls2dXU0yoXHC/uS886ARK1A3vcup3HyVrE8DukH3OulYnUPudf6bap85q/HJ/7g2qciqIoPtGBU1EUxSfG2oonzcNFHdPAHmnKdyUzyTJ7sOFybyvgzJccs6CTuIvcOMEzCUcOPQ8AO12yqwSztKx42XMtmXvUK8XuEVw4AKjrZFc5+ZiSpuC+BOqL+0toVp9g1p19N5srjcl2wkxrbc8KG8YZteu2sIcfdR1PPONFa+2x4l5yw98kZrz2GxWbT8UyH33yOuDFuOcWycLP5iLPbaVrao1ibWoYLyro5NMvBmB7e1kkHP/vxwDokOJFHgUXgIKRZcfNPsOtq3myLDrYgtC4ldJJVLkGn9fAV5773YTsdwHo+rnEnLd9RcaP1PXe4qjZIAt5hetKRnUmdZforpNeFbewY2tKXPmdJ54X0kjkseDKRgDMOudxt+rcLC+6DGDAL3KP0MXkD7rJZm02X6YDQt3M/GzJU55cVeNUFEXxScwtDgX/4Rs947k5uC7PjlvDY+27hpwxm1CKdonje+tLvUw76+fKv+Hxz8siU5sJnmvLxl6iRTZYWrFbRVDTDG5xCpCyPb/C8xIds30XqZ/N4LZThrllvV4VuUwZKW5FY++SxbYGyZ6b1zN/iPaQ+1+pSzrXy4IT5LgHZJGn2yWSp+DFVt+5ddevEavk99tlceflF55w6xbfJD/tYQd/DcBfRsh11h/uaawForDS8gv5zdX4dLpbFz07LA44w9Mm+78hmuGyAeLGVyJdcghBjT6YrR2gfYp8xxsKpSzoNrji7KZumxYPijZab77k5g1ahQB5fxJZp3wuFt6Eu8Q96b8jH3PbfNRGfhenvTcNgINSvGxJT198DgD5dSRLV2UsxdJQjVNRFMUnMadxhovQPYguyZZ51VZ75J8sdA+SBr9XfK3g9qbB+c8F93sa76hB4gIzdpD89Z74roT/fdLVcxo+UCj6fb57/FMfcRPrdoXMhf1l+EcADMnY5rYZ0uV9OXiw5LWCezY1/UayLN11u4TC9p/nhWEn9ZN5yBptpc0/c05y6xb3HQ/AEX8Xx+oG74pF0fpdv59KCQalAOS95WSgEsWPrk+JfNO2ejp6rkQoY5OkrDDDe+JStojGn/20WITnfCEaX82jS4ZMNnlTLMyfbvesut03itWX8rm8rzVRtMprfh/mtjGFYkE8Pb8vALtWehZix98lYMVUcY8y1TgVRVF8krAaZyhFe/ZU3KgctneTJAcZG0SzqdnS+7daky9zpPPukNcJdWU+5RN6Veme8U5wrrn5R+KcftJNoj2cuXiw22bbPeLgvKWDrIbPustzQP/yXQm13H29aA+7nFX61CtC5iid15xRElZ5bt0Fbl1wpb3IW2hXwsDmg0WLDH6/rR4XCyv0GXt7hWR3P/klWVNod0vJIIKg7B78VSy1Z4/wgheCiXKCmu4Fb1/v1s29QDw3Tu15CeDl6C1c4AW1BGl+Zsn+h2vHy8rk42xpjPnKGDPXGDPHGDPCKW9gjJlkjFnkvNYPU5+UKKByTUxUrtGhMqZ6AXCztbYL0Bu4xhjTBd1uNN5RuSYmKtcoUJlExjkgCfastbnGmHlAcyK83Wgskb5ZHGkLDm8PQOtbPAf4NzsMAuDuUbITQY+psoVHq33cpGKNaMm1aJx8d1nJkhRg/qRsty5rnjgjN/5S8qSOvNZzVG7VTxYPAheIY/MtYySouWjpvBL3aHyamOiv0sIteyP7OAAaLY583HIsEWm5Nu0iDudjtsoCaWnTYC2SZeqkoGbFTl01fhB3pOO8FAI86OSrCC42Zj/imeGn9pQMZZjqzZPqa47T2av5MGAaut1owqByTUxUrpGj0gOnMSYDmAjcYK3dbkJG/HBsNxrLJH0jIZ/bLpQs5LlHeyFo+YeIc/DjY84GoNUTZW+NGotESq5Fx8gE/6RO450SWdSZe9V/3DZdEFeWlveJxvnfsZ43dW4bmcZvl+NojDkhG6mVQaBj+9I6WuF5iUik5HpZa/l9P72wLwCZzN+3iS8O+q9YEB0zvXycbRcXz7xUuCEkMOLPwYPVVbpvVamUO5IxJgURwqvW2necYt1uNM5RuSYmKtfIU6HGaeSv6nlgnrV2ZEhVxLYIjlXqviLaT91q7kc4iLRck374FYBjrv8rAMm7RYNMX+PtBdXy12nFzsl82tPWM/GPya84IUeiExG5huwHdG7t5QD8e07Zi/LT9ko4Y3KrindFCIYxt/lHKSHWMUxlTPWjgYuA2caYYHbhOxABvOVsPboCGBKZLioRQuWamKhco0BlVtW/B8pawtLtRuMUlWtionKNDgdE5JBSDTiLMrUmFDfHI7lUc+qHXnajYJxyadEjik+KvFyXA6+X3dbafysRcoWlNL/qZ9mO+4HuMhswjpLbLsc7GquuKIriE9U4lbgnmOE7NO9iaEYcJXzUfEcsiNI0zSCt7pbaB48UzbMhFee6jTdU41QURfGJapxK3BPcRyaY3Ru8vIvx4NqSaARDJRtWItdtvKIap6Ioik9U41QShuA+MlD1DN+KUh6qcSqKovhEB05FURSfqKmuJAz7u9WrovhFNU5FURSfGBvFfIXGmA3ATqDkXqCxTyOq3u/W1trG4ehMLKFyVbnGIBGVa1QHTgBjzAxrbc+o3jQMxGu/o0W8fj/x2u9oEa/fT6T7raa6oiiKT3TgVBRF8Ul1DJzjquGe4SBe+x0t4vX7idd+R4t4/X4i2u+oz3EqiqLEO2qqK4qi+EQHTkVRFJ9EbeA0xgwwxiwwxiw2xtwerfv6xRjT0hjzlTFmrjFmjjFmhFPewBgzyRizyHkte5u/A4x4kK3K1T8q13LuG405TmNMAFgI9AdWAdOBodbauRG/uU+cPaebWWtnGWNqAzOBwcAwYLO19iHnR1TfWntbNXY1JogX2apc/aFyLZ9oaZy9gMXW2qXW2jzgDeD0KN3bF9baHGvtLOc4F5gHNEf6+5LT7CVEOEqcyFbl6huVazlUaeD0oco3B1aGvF/llMU0xpg2wGHANKCJtTbHqVoLNKmmbkUcnyZa3Mn2QJUrJPYzG0257vfA6ajyo4GBQBdgqDGmS7g6Vt0YYzKAicAN1trtoXVW5jcS0o9L5ZqYcoXElm205brfc5zGmD7APdbak5z3fwOw1j5YVtsUUk9Mp1YVuhvf5LJlY6wng/Aj12D7FFKnqFxjW67g/5mNK7nWrukeFiUbAJK27KzSJcuTa1XycZamyh+5byNjzHBgOHBIgGSONP2qcMv4ZrKdsKK6+1AJ/MoVlWtcyBUqIdt4lWthz8Pd4z0NZQuVWhOnVema5ck14omMrbXjgHHGmEEppH0U6fsp0SEoV4A6pkHCmrcHGvEq18Cd693jQ+tINrklEyN3v6osDq0GWoa8b+GUlYq19uMq3EuJHr7kqsQVKtswUZWBczqQbYzJMsakAucB74enW0o1onJNXFS2YWK/TXVrbYEx5lrgMyAAvGCtnRO2ninVgso1cUlk2Q5t/pN7/Ni8EwA4iMj56ldpjtMxv9UETzBUromLyjY86C6XiqLEFEnp6QAEPpXw8iVfZ7l1bR6aBUDRnj0AmJRUAM7O+MNtc/+SOpHvY8TvoCiKkmCoxhkkKSCvRYXV2w9FOcCxBQUAnNB4HgAfDv/ErXt1aEMARo4cAkDjmbkAZCR5c5xD+k0BYMrnbQEwIz0f9tRPp4elj6pxKoqi+CQuNU7bp5t7vOZ4CQlr+qPMeaRs3AXAxl5e+r1Gb/wKQNGuXSWutf6aowB49KZn5LXrEdLWmUNRFCW6BDXOzwdLNNATd3jRS3f3+QCAmXePAeCHPUVOjacDvrvkUABqpecB8PLYJ9y6yTs7A/DWnQMAqP2bOM4XrVzj3X/v3gr7qBqnoiiKT3TgVBRF8UnMmOp7TukFQG4LWaRpPHZqmW133p3rHr/dSVT2Qa1vAKDzKFHzp98/xm1zWPrVAGT+Z0qJa9XYJKp+vxqyKHRvf1Hz0z/4qUTbIMnND3KP/xjaBoCG8/IBSPsoPJPPinKgU7hoKQAdLvXKXhoguZS/u0cWjp5v9X2J8+46RFJijP6bLCBdtXuEWzfs8fcAaHnzQgB+/UhM9zYv57ltClZVHIWqGqeiKIpPYkbj3Hz5DgAu7yBa4Sdj65XZ9rLWnuZ4UDD33h75DyhcuASAhfleLr6t3UUbzCzlWvU+lrCs/MdE41zbWzTeNh94bQLtxQF32QXNAGh1nOdsO7vzf4pdL+u94QB0uKpsjVVRlP1jb115PoOaZvB5S90YcNvcfLZolVf8S9IjvdqltVv3r3fOAmDyhY8A0K9eJ6ByWmYoqnEqiqL4JGY0TmMk9V+gnAz3yW3bADDmsT5u2eX3ylxm0l7RPHEy2v875yS3zXP9XpCyoy+Se/3wi1tXuF2y7C8rcNyP2oumWvf7hm6bV7MmAJBivH+1IL1vvRKAzafsBmDOqU8DcNaYi902Rb/NL/MzKZFl4Qs9AWg4RZLbNnyu7LlzpfowaWnu8YKnZJ0hOBR0usV7fnLPk+f1xz1iIXa8Xp5lm+/NUT7YYiAA0054EoDXa3R061p+Ie2+O0u00Aaz96+/qnEqiqL4RAdORVEUn1RoqhtjXgBOAdZbaw92yhoAbwJtgOXAEGvtlqp0pKhIxvDagd1OSf0SbQqWLgcgc+Nmr/BeeQkETXWHKZ8e6h53PVuiAmyStElu5JnhW/tlA5BvxYT77ZjnAfhmt7f5U9eXrwWgMF1shyXnjnXrav8hUQb1H5TXmsdLtpac4xu4bZr8VuKjVDvRkmt1c/IhYovt7iKm+qrnqrM30SGeZBvMhFT3C+95W5b1LAB7rSzqXtBloFv3RRup6/3F9QBk588Eipv6rxwvbU6adTkAmTs9Uz/5C2n/ckdJhF+P/Zu6qYzGOR4YsE/Z7cAX1tps4AvnvRJfjEflmqiMR2UbUSrUOK213zobvYdyOtDXOX4J+Bq4rSodyVsgOfSGHiluAYXzvDH9gS/E6TVlm5Qd1GsN+/LRsIcB2HmJfKRFeUvduvvnDQLgxCd/BuDeTM9JPc184RzVAGDs1uYAfNDvELfNQYeJU/3Do8X16B/rvR31kr6Ta1onL+AfBeJWlVe3/M9b3URLrpEk7yRZ+En9bEaZbT75/jAAZp8jCwVnNz7ZrSvcsKHCe+Se2xuA+t+LC1rB6pK/vVgjnmS76P7uACxo47n1dZkiC6t7VmcA8Owpz7p1mQHJTVF/qjxvRceLfLfe6rkf9k4TLTJjfOQewv1dVW9irc1xjtcCTcpqGLrdaDo1y2qmxAYq18SlUrJVuVaOKrsjWWutCfoSlV5fqe1GW33uZCRxvHiG1fH+2Y865XEAOqeKIOfk7Q45UzTFdiny77SxUP55lpoit8Vzh74MQL4Vd6I0k+LW7SoS94Qb1xwPwIqr2wGw6P8y3DbTzn4MgPpJcq9/XO1pnAbJvBR0h7iy/zD5PMtnum3iZo/VEMIl13CTVLu2e5yyPb/C9q0+E7eVmueKhrLx5PZuXf3xxTXOQGMvb+O6F2SOfWYPmc/u9oiE7TZ9PPY1zoooT7bhlGvRsaINbuhewy0rcMbiektELpPOeRSA7j8Nd9u0PPt3ADZfKm6HE486wq3r1/xHAL67UzIe1UwSueZbL49uh7evAaD9/36sSvfLZX9X1dcZY5oBOK/rK2ivxAcq18RFZRtG9lfjfB+4BHjIeX2vqh1JmbEIgNMXDAbg004fuXXT9rQB4NS3JVzq0CMXu3XXNP8S8JJ03LBS5rA2D/A0znXndQVgwt8lzOqOdUe5dRvyRIN5tuUPUvC+zI/sKPLycf5z/TEAPNJU5jMxxVfwQylcsLjMujgg7HINNwvu7+oejxoklsTYQbIOEkwKEUraZJHZb3kizx2neAli6o+X14J+PQC4YLT3cU+tJXOaHV66GYCsJ6aFo/vVSURlG+joafI5D8uwMqOneKgETHn6mVh2TUellahJPXcdAP9p7mmOV6+WOedPp0pO3pprxIr8+ppH3DZFdQr8dt83FWqcxpjXgalAR2PMKmPM5ciX398Yswg4wXmvxBEq18RFZRt5KrOqPrSMqn5llCtxgMo1cVHZRp5qj1UPxp8fPHE5AHc3Fvegjs97OfSy7pctQbM7ir/u7Wd720L3SpOFnhtyxDXlpdZium+a4y0gZQa+BeDWtccC0DzN8/v9+EUxw7sjqr91rPAW73gZkAobOW4NH4nZt+Ewb7Ux84dKftBExhhMSipL7uvhFg08QVyE6iRXvAXJ4p2yKFM72duyoG89cVqulSRlS/dKbqvVCz1Te02+LOBs6i0LxBvv8txPTuok+Rq/Xy2Zrc6ccjAA845/3m3T6ZW/APBr39EAvJbb1q075yIJesj6WmPbQwk+r8FglMI/yULpfS8847YJPpOjtsj3+fnZ3uKOyZXta2q8LnKd0G4yAJtu9ra1OW6kDEujmr1T4v4/vCb36/SxTNEGp8aO6na122Zyv1EAXFf/VGmzJfx+/hpyqSiK4pNq0ThND2+C/7o3JfNQ62T5VzjuHpmMbzfRC5NacZNoMp9cJU7ujRwXBIBb14rLw7weMiF8Yr8rAFh/radxBr6U3J4HfbkJgEcmvenWjXccLpo8VTw7fLHp5dXi/hZ0bt/a1astLcfngUZBw5psHNyDRRd7WfcvXN4XgJ/Wty7jLKidJlrH6PZvANAu2XNb2WvlO3Wsw0UAACAASURBVA5mpEqpJd/9Tb1LLgBd+e8xJcpcnIWFVY7sivAWIZb8+UUA7t8oTthTzuzs1gUWzyr7mgcw27uJdr/zRMlN+9Edsijz5W5PzncuFTei/3UUjfGTeSVz6258SLTQbc/Iczqrp/dMfusYKV2fFi3yzkted+tqn7QWAPOet/gL0PZh75kc8fg5cpAcuUUi1TgVRVF8Ui0a59qjvLmoATVF65iTJ5OL79wl/2C17/bG9PqBrwD405wLANi005tjfPIQ+af6DUnqEQziP+gLSlBwVLcSZcl7KuHjWySuTk9sOA6Arp1XulUVu2AnPsZCYJ8v4oQGklm/yIp1Mf8VybSdHLJD8+V3iKaZ4oQI9Lvir25d2sfF924K1JGQ3IV3dXHLFp8vzultP5dkDo2/9CwRe+5GAHbukbJ6tUSzyVnvaT9/Pew7AG5oIDkdO3yc49aNP1nWUUpzcTqQya8lz+n0O2Ve+ILlpwGw7r52bptLRomnU4+pIpdWeEkvk2pJyGRwb64JuTIHPXNHG7dN0P2o2RRRPf/W6hy3btrJEgzz50fFYb75mVJuf57j9bHvfn00X6jGqSiK4hMdOBVFUXxSLaZ6k6c9F4+eu68CYHs/seE+OUpMgHd2eq4hYx8+A4AGLzrn3exF/vTtJZPEwx+SCems28t2H0maLi4qobHuW44Tc6Dhs6WeUoz35oupf+Nhk92y92lYVvMDhsCmndR7eSpte1zpln1wuphUw7KcyL47vyrnChI9suFyz45v8fE+TZx8i9PPHekW9f5FEhtkD5PpmeSWLdy6paeKq1L+crn2x0MlEedZF17jtvnyazEbJx8vv8EJr3oZem4fIS5S2deqqR5o6OWWvfOe8fK6XhbUZn8kUzD5l3jZiR4fczYArZ4ouR33jb/KJoa3/i5tLq8r0yQPfHm61+gMMdXz6snwlPWOtxCUeZrIbNdKL2dBdaAap6Ioik+qxwHeegsywc2zGjqZuR+bfgIAJ9f3NlRr/IPj7Oq8b/GKFw9+6LESJJHWcVvFt3UyGJ076y9u2QzH+fmIV0UT6XiLLBAU5KwtcX7HmyUzzgfNjwspnVOi3YFK9ggvpvjMHTcBsOBScRUacLIs7K0c6C0MzrlWNLzgVs67NtRy61b9TayK+gtF6nvqy398/YC3MHhr+88BuOVFWTzodJUni/oTRfscdIdoun9dITkMArtKLucFdsjvIoCXgyBpb9n5CA405j+W5R7/Kf1TAEZdLi6CLb4pqVWWR72AWBVTe74EwID5Yk22f80LfkCK2FtHXNFqvOtttX3CBZcB0HGGyLq4U1L0UI1TURTFJ9Uecrkvi2+QOZN6//X+yVafLE63TRcuAaBwnZcRq9lg/9mxWg33tMlTXrkQgBHdJVTz40xn/rQUjbNgrWRrIfiqVJ65YiW0nOsVte0g7ipLT5QwyIWneo7spW3FvC9nZchWsWedJOcvW7DDrTtpimwJ+6cMueHcXHHYXv0nb25s93mSaWfyWZITckG+587U8SmxLiKfZyeGqVUD270bC/qPc4s6vC+hqB2++amss1xMsgwvGy/1Qi67pYob0uZCR8u/yNkWPLVkWGRhyYRJFKaKrhfIzS1ZGUVU41QURfFJzGmc5geZ27y3vfcv1bTI3zxKRRRu3OQeZwyQ409byh5Dy50EA41f7eW2CZ1jUaqG3evNZWVfJrL+ZYmU3b/K2w8omPwh+xVZ8W74q2gmNTZ5mb43d5ZkEjNueQqArBQva/9njndGsOzoLGdVf0TJ1f2jf5PV+brXe/OahcuX+PtgCUheE1h+veWPAs8LpfOdjtVXznm7B8uz88woSbbROdXbE2rmXpHjg6sk725pezj96VJZg2j0tYS9hoaolLe/VDSpTD7OlsaYr4wxc40xc4wxI5zyBsaYScaYRc5ryf18lZhF5ZqYqFyjQ2VM9QLgZmttF6A3cI0xpgu63Wi8o3JNTFSuUaAyiYxzgBznONcYMw9oTqS3Gy0qzxgIPwUrVwGeG8uJ937t1k2ZI/HRiRS3HGm5Gkd8hdZxGCkSg8v28fIFBHaKif5hrrgjpSaVlHnmdDk/4+2SW1c0Fc8YOrUWV7IlQ8a6dVeeK5l1Vtwk9/316BcA6DPzQrdNjVRxTcoYIHKN7i8uMoRTrh0zNvDZ0WPo/dX1bln2RjGfjbMd9tZzJT9m0yuWuW0+y5bFpJwCkd3EHXXcugcfFre0zLfKduMLmuOxvMmhr8UhZ6/mw4Bp+Nhu1BgzwxgzI5+9pTVRqhmVa2JSVblu2lRdXpKxT6UXh4wxGcBE4AZr7XYTsmFZtLYbjQa13xAn7hdP7uOWHTl+OQDbzm4KlO4cH69ESq5tX5bvqOdacV/JzJcFvp13e24km6fI97l84p/lmqF/41fIIs6WDuKWlEHZHPSN3L7wHO9BXzFQzsi6dzMA3e4Sx+nMV72cn+nrE3fAD4dcsw7OsJ/ubM3bx3qa/BuzjgTgsgZfA9A5VRZOP9/lbbmd9Zm4mS08UTTPY2t4WaeeHS/uSIUF8e3oVSmN0xiTggjhVWttMJ+9bjca56hcExOVa+SpUOM08lf1PDDPWjsypCrmt5KtCu0v+tk9rjVNQgEHfCV5BV/t1KLUc+KJSMu1cLHMeWUuXlas/LLWnmvZA+sHAZB9ccls6z9e5IRaZlesFdb8n8x/9uUqt6zt7Jxi/Wg9pNJdj2vCKdfNS+vw+tknUGvMRrcsNy8dgEEzZU+wZl+IRZC2xdMgO69yrIoTS14zqbYEIERiH6BoUhlT/WjgImC2MSYYQH4HIoC3nK1HVwAHyE8zYVC5JiYq1yhQmVX174GyMh7odqNxiso1MVG5RoeYixyKRdYMldyMo0aJid6YBdXZnbgkuK3smMe8RbfOXzqZqEppf/4H4mJUe1nlHT+CJjskhmtRdWN376Ho9/nkHluyrgOrir3Pnu4Flk9e1gGAcxbLVMyZTWa6dYVbt0agp9FHY9UVRVF8ohpnJShYuhyAxqdVbz/imeB32NB5hfIzD4Xm9lRin161vdj+zxeLU/yqSeISdvE/P3PrxveTTO8pk2cSz6jGqSiK4hPVOBVFqTKhLnpZyK4OwbDMQ+pf7da1dDK3x/sctGqciqIoPlGNU1GUiBDc4+ugh72gh3jXNIOoxqkoiuITHTgVRVF8ogOnoiiKT3TgVBRF8YmxNnopMo0xG4CdwMaK2sYgjah6v1tbaxuHozOxhMpV5RqDRFSuUR04AYwxM6y1PaN60zAQr/2OFvH6/cRrv6NFvH4/ke63muqKoig+0YFTURTFJ9UxcI6rhnuGg3jtd7SI1+8nXvsdLeL1+4lov6M+x6koihLvqKmuKIriEx04FUVRfBK1gdMYM8AYs8AYs9gYc3u07usXY0xLY8xXxpi5xpg5xpgRTnkDY8wkY8wi57V+dfc1VogH2apc/aNyLee+0ZjjNMYEgIVAf2AVMB0Yaq2dG/Gb+8TZc7qZtXaWMaY2MBMYDAwDNltrH3J+RPWttbdVY1djgniRrcrVHyrX8omWxtkLWGytXWqtzQPeAE6P0r19Ya3NsdbOco5zgXlAc6S/LznNXkKEo8SJbFWuvlG5lkOVBk4fqnxzYGXI+1VOWUxjjGkDHAZMA5pYa3OcqrVAk2rqVsTxaaLFnWwPVLlCYj+z0ZTrfg+cjio/GhgIdAGGGmO6hKtj1Y0xJgOYCNxgrd0eWmdlfiMh/bhUrokpV0hs2UZbrvs9x2mM6QPcY609yXn/NwBr7YNltU0h9cR0alWhu/FNLls2xnoyCD9yDbZPIXWKyjW25Qr+n1mVa9lyrcrWGaWp8kfu28gYMxwYDhwSIJkjTb8q3DK+mWwnrKjuPlQCv3JF5RoXcoVKyFbl6lGeXCO+55C1dhwwzhgzKIW0jyJ9PyU6BOUKUMc0qJIZlFRLtJqd72S6ZTvebQpA4zFTq3JpxSfhlGsiU5XFodVAy5D3LZyyUrHWflyFeynRw5dclbhCZRsmqjJwTgeyjTFZxphU4Dzg/fB0S6lGVK6Ji8o2TOy3qW6tLTDGXAt8BgSAF6y1c8LVsT/ePsQ9ntnneQDGbesAwCdd64XrNso+7I9cmxy8m+vfm8/o3ke7ZYUbN1X6nsvHtwXgl4NfcMv6jbvWV7+Vion0M3sgUaU5Tsf8VhM8wVC5Ji4q2/AQ8cUhv6wdcRQAtx0ywS3rOukqADr/a4tTsjRi9w9ki/ZTuChy90g0aicVcUKNXK67q71bln19JTTOXmJV/HbUeAA6vX2dW9V+4o9h7aOihBPNjqQoiuKTmNM4d/feCcBLN3hhsR0+nQ5AYZjuEejoaUYmvwCAUz+UexyUshCApy8+x22TXycFgNTPZoSpB4nF3B2N6D7lMr4d/Jhb9tfHLwCgYFnZLo4r/0+8Xf4o2A1Axwc9LT9cslaUSKAap6Ioik9iTuNMmS3O0Ok/zHbLiqJw36fn9wVg18raAHT83VtsNLm5UehB/JK2poisu/bQZHINt2zJpQcB0Pqu4hpncA4ZYGrvZwHo/uFNAHRY91Oku6ooYUE1TkVRFJ/owKkoiuKTmDPVa/8hhnnB4d4CTvKsxQAUhclkLlywuERZ8zOLv4/G9ECiYPfspXDeIh7Z5GUoa3PMH1K3T9tlFzR1jzNMGgCdH98M6IKQEj+oxqkoiuKTmNM4674ijs9Fxx/mlu04QTSZOr+uA6Bg6fIKr7P2xqO8aw6QRNC73hZtp+FzmnEnEjw7/Vj3eEr/UQBMXyQZj8aePBCAPS3z3DYz80THLM0C8EOgTh0A9vbMdsvSflsu194n9HPDVX3c4yuvfw+Ad7pL3gu7d2+V+qHEBrnn9gag5nr5rQW+mhX2e6jGqSiK4pOY0ziDJH3zs3tc03kt8HF+8w/XusdL+2QA0Fo1zYhSe26qe9xsoHznm3fJ67ybGgLwXN/n3TbZyfkAmDSZ6/Sr8SU3EwviuM+XAHBbw2/durafXy73GCYaZ6CzaKNv3P6o2+b2FYOd+27wdV8ltmlwlbjADW/+DQBje/R06wq3by/1HL+oxqkoiuITHTgVRVF8UqGpbox5ATgFWG+tPdgpawC8CbQBlgNDrLVbyrpGNMg7SdTx9CkLAFh/vLcbaLPn86ulT7FM2OVqDKdc+L37Nt/Kws8TT50NQMtVMtEy+1gvAXm/GssBuG7OrwD84/HL3LrM0VMqvOXmFyTK7JYGC5wSTw/4+5GyS8uoW8TP7JAz5gHQIERVmJPTDIC8MVkAJG8LuHVZ7++SjzXl1wr7EWvEyzMbikn2hqIF47rLQZ4IK2OJV1d/kfyOak2SyL6inTtLXGv3fRK1NvBlcV8c8XAnt67TzXKeSZVppcIt+/cVVEbjHA8M2KfsduALa2028IXzXokvxqNyTVTGo7KNKJXaHtjZ6P3DkH+vBUBfa22OMaYZ8LW1tmNF16ljGth9d81LSk8HoMhZGNhzyhEAZPyW47Yp+GMVAGuvF1eS3MP3uHV2t/wbndxDNIPJyyRLfOuRxm2TvF4mhCvjxhRJJtsJM621PStuGR3CJdfadVrYHr2v5cuXvYWf7g9dDUCTJ8vWHHeeLRssXvWA5F6tleQtDj1yxwWlnpPT1zteesYzAAxedBIACz9v59Yde7osLj7ToviCYIeXr3KPHzzzVQA6pYqbW6eUNLdufaFonBdeOgKA5C9mlvk5Yk2uEB7Zlva8RoqkmjXd43bfiLVyT9MvAWgUKLlF8W95MgYEnBCLFiG2c92kGiXal8W7O2Xx8t+LT3LLNm2VsiXn3VmmXPd3Vb2JtTY4sq0FmpTVMHS70XRqltVMiQ32S65p6bqVSRxQKdnq81o5quyOZK21xpgy1dbQ7UZrNWppt57chzP/b7Jbf3wt+Sf/bpdoirc2GAfAI5s97WH8AnFondPnPwDkFOxw65olZxS7X4dJh8vBj56m4ceNSRH8yLVmk5Z2S6e0YvUHTd4IlB9GWWvCNAAOf1S2+u6c6j2og594ptJ9fTJrIgBDlt/ili3vJTk+//GLZJm/P1OybbV/aK7bZtztwUxN8lp0THe3btJb4wHYki1zYY2/qHR3Yp7yZBv17YGNWIarrvW++ycyHwE8TXNXkRc08f5OGe9HLRFNeN2KBgAk7fZmHQN75ZopufJqQn6E+RnykfJayDWvO+IrAKZ2m1iia4ESJR77u6q+zlH3cV7X7+d1lNhC5Zq4qGzDyP5qnO8DlwAPOa/vVeak7Obr+Ohfj+4zZyHj+sStEjbX9u0rAVh6zli3xa19xMG5/WtSV9TY+wda2t/bGRGgoI6k5xg6f41b9s1WmcpZf05dabNylVsXnFtZfov842U9KatuhVu3VeYjJRr7JVdTBMm7iisnRTVTy2gdeqJoBB/uEK3wsxDV4IPris+treslGu3v1//HLTtklMyjHvSIWBd1bcl9ipqkyPx2cJW/PLnuyUwrUVZrfcKke9kv2YaD0B0XFtwp+W5NjqxtND1E5pdnH+rJddAC2X1hzwPi9ZA2ZZ5bV7RL5p7rsth5rRofDJDf2YjnvbDfQfNPc45GlXlehRqnMeZ1YCrQ0RizyhhzOfLl9zfGLAJOcN4rcYTKNXFR2UaeCjVOa+3QMqqis9ymRASVa+Kiso08UY1VD2Com5RO398Hu2X2Scmek/6hbJvQ4TAn56a3VxrL8mUxqP3fxcUk/5iD3brek8R8H33fkwAsOENU/hTjTe0OqyPTOVl3DAegy/2e+TX/3zLZvOTPcl6vI+XGm+d6uSXTNotJWXOdmKON3vzNrSvNAfdAIynPkrGm+BLc5n+Ka1Gjm8RMC2ZACnTwFv1yHpFN8G5t8AYAhz1wtVuX+WVxN6baTXuXuG/TabIARCkudcH7DK3zMgDbHJEH4+LBi41PbtEcgGEPeNbrt47HW52pEvesC4yls3twLwCOudubJjmutgQk9EyTPKuNAr+4desL5Xk55lVZyPvG2QY8690r3TYdrpaxIAWZbgvnZEly2zYAzLtLcif8fsJoAP4o8Kb/Fi46qMLraMiloiiKT6Kqcc7f3YBjfz2XuoNC8y8uL9Zm4WXiXlRovf+Z57eI47urIYQ4I++9RvJu9kgrvhixsdDTBCfvaiH3P03+XUYf6/n9ftTg42LnfXzoeABqd/eul2ZSirU5ZoiXLr7WwGVyUIlAgkTFbN9F6qfT6fIfT2P86cqRAGR8lb5Pa0/7WOW4lWX/91YA2o6ZVuY9UreX1DvWHy6Ozs2miKwKQiyRa8aJFrutSOTSLkV+V2ve9DaL27VI/E+fOONFAI5yNCSAwVfdAEB6jm4gVx4pubLoNnmN90y9uaUHAHaTaPfp6z39rM1bkrUs81CRZ+BiJ6xyeRiHImfRMRhMs3qop01+d8zT0icj9/3XRgnC6Flrmdtm9ilivZa38KQap6Ioik+iqnE2SdvOTe0ncde957tlWRMkyH7d0fUB+PkM0VR+yfPmKKdudJIw8EeJa+YX939nW5HMe13Y/s9uWVBT/dfNMmf+282e68OPe+Qf88a/XwNA/V+d/W/mLnTbBPM+Lv2raCvzhnvn9xguIXyNntFcny3v9+Ylh7wlIZMrzpI55Pw6ovlZLxKW7OfFFaXtooq/u5rfiEvKWzs8PeDXW0UOhbc42ovxtMP3d4qb2dXniHwuePkTAGYe8YrbJqWX/MZuWyeuaCfW8CyZlSdKR7M/rLBrBzRB669+SIBA/XLaFybJd154hKxt/LBHZDf1+pFum0O7yLPYfpzMLJeWaCU4h72njdxt9eWeVvlMT5Fx3xqyJrIw37M+z557MQB1bhErpej3+QBMx3OZGpsSXN94rczPoRqnoiiKT3TgVBRF8UlUTfW6SfmcVHMtQ/4yxiv8S/E21685DoBj6nimco4TVdSSkuzdJ5z29e2icpe2DUOLTyR+mpu9suX5jQCo87q4U5QWW12QIxPaWa85EU/DQ+rSTSlnKIULJdqrxYNLym7j43pJGfLdZwa8LaJ/cWR829KzAFj7QSu3rsW7TnTYcolRv/dDyQt67tCn3DaD+suUUeEccZ/pNuESt+7rwY8BcNUj5wHFo80Uf5gUb6F187utAfjpMIkM/Gmv/ApqGK/N7yfI+FDzRCkLjVWfvFsW9E6uKRuwBZxFnr3Wy7m7zWl/2P2y6NhskreNzrdfi/tT+xvkIe6wz/gDYPPzShbug2qciqIoPomqxrlwV0P6/3oxEw550S1rFhCXkqP/fi0A9V+WCf4/vvIcnq/vIhlM/kfjEtcsaFg8u/szi2SL2kzml2i7q01JB4Pzasvi1AtHnw6A+eGXEm2CbDoys0RZrXUJE8sc08z7m2gqvdK8XKy9ZwwD4M3ukgf0xtF93bqCfbSGDs84OS1CYmoWXioLC+2cpEotHvceh1Zvy6rj2kFi5zR6RjXO/WXZ3T3c47ndxSWw8zPyvLf+1wwAltzntVl0sWic/1gvOQxuaOg51980fQgAmb1F5hO3yjbiU//Vy23zzRNy/o42Yo0WLlrq1rX/QBztl50mWdhumCnpNuf18BfioBqnoiiKT6K+PbC1hll7m7rvB9cSJ+h6CyXrCUUy57HsHS8078rbPgNg5L8ka0m7N7e6dY8f/0ax6+cuFC2ipG4IgT1la4drjhH3lZa5nUrUre4vOf9ev07mvUZu7urW1Zskc7F+5uuUyhNoJKFxH532OAC9Z1zu1qX/T+a7OvcS2e05oZtbl/bJ9GLXCWodB39zhVtWVDyugcAvi9zj4JzZrmY6h11VnjrvOff4uNky15z1msw7zhsnWuXdfUrmw2yVJls7/2WpF3DS7nyxCC8YKS5LSU3FAmk7wQueOOJiMSveHSIuTjf9Xx+3rsPV4j512G8SrJHnGKEtqHiPq1BU41QURfFJZXa5bAm8jKTat8A4a+0T+7NrXkFBgI0batOm66aQUgnL2nioaA2NnYG/+SveHOWWW0QbXTjMWY0f5p0dDK28eMVAABZfIG3aZno7JrJdVIsON4lDbGiSka8PfheA30c4Tu0jyu7/tav7ArB0qJcEoHDTsjJaxzbhlGskyTlPQvnap3wOQLOHPDUxsEhWw3c8IFrHyv5e0ET7T0q/Xtvzy57DDk3YctS91wOQ9ZU46ceLRRGLcr3v/7xnsd5PMlfc/zPJezuhrlhsPaZ6lsSwo/8LwOcbxRF9xdue9dl1inhSBAZIJv/C7dtL3K/ZcLFIhx8rYbMZhITyOhZt5n/8aZj7UhmNswC42VrbBegNXGOM6YLumhfvqFwTE5VrFKhw4LTW5lhrZznHucA8oDlwOvCS0+wlYHDpV1BiEZVrYqJyjQ6+FoecLUcPA6bhY0fEIIGdhnoz0ni9+5Fu2dY6ktuy27DfAVjj7JhRuMnLVPPQRsmAVDcgceh3NFrg1vV71HFyHS1uTFmjZfJ/2anPlrh/56YXATCpk+eA/9dV/QGY8/ChAOxuUPK/pP5Cxzz4epZTEp/meVlUVa6RpOmLEqc88HeRa+DHWW5d0Hzu9pXEo6dvCN+UfTD3QLyY6KURK3Kt+Y5nKgedfj7pKgt7nyBuRK1TvGe66y2ycNN6jJjzuX/3glzOaCTyf6GRk4uiFFO9YK1Mr2S8vS4MvS+dSv/SjDEZwETgBmttsd5a2Zy91LxqxpjhxpgZxpgZBbs16W+sEQ655lMySkupXlSukaVSGqcxJgURwqvW2nec4nXGmGYhG9yXumvevtuNZo6ewi+jvfppA2VSeEN3mfQvzS1g4mQnH2dAZH3Hed6/U2quk3WnQP7LOvxV3FB6HDTEbfPT4eKy9PtRYqmsD1EjVg0Rp/pay+VfMXQbuUQnnHKNVB+DCzaetl+S9hf9HKnbxyXxINcS9w0JWGjxoIwBwcd05OCX3LpaSTKYFyxdHq2ulUplNmszwPPAPGvtyJCq4K55EOVd85Sqo3JNTFSu0aEyGufRwEXAbGNM0JfjDmSXvLecHfRWAEPKOL9cgo7KLcpwHwFod6vMNwXqSLKPUw4f6NY1+H1Hqeds3erpjnOcf7NDUyUb+eB/3OrW1Vt+wObRjKhclWojceTaW9Yd2qV4z+idfwS37t1QDR3yqMwul98DZYVP6K55cYrKNTFRuUYHjRxSFEXxSdRj1atCMEqgsG/oImFOqW2bvevl9xuy9CYAaq12tvd9+YA1zxUl7thUVMM9/m2a5NttV82mumqciqIoPokrjdMPtSZOCzmuxo4oirJfLLpQNM3GSbvcstafVJydPRqoxqkoiuKThNU4FUWJb/7eT1xNL5t3kVtW58uZZTWPKqpxKoqi+EQ1TkVRYopgoMsjsyU7fNur17h1sZJ0RTVORVEUn+jAqSiK4hM11RVFiSmCgS6th8yW99XZmTJQjVNRFMUnRnKaRulmxmwAdgIbo3bT8NGIqve7tbW2cTg6E0uoXFWuMUhE5RrVgRPAGDPDWtszqjcNA/Ha72gRr99PvPY7WsTr9xPpfqupriiK4hMdOBVFUXxSHQPnuGq4ZziI135Hi3j9fuK139EiXr+fiPY76nOciqIo8Y6a6oqiKD6J2sBpjBlgjFlgjFlsjLk9Wvf1izGmpTHmK2PMXGPMHGPMCKe8gTFmkjFmkfNav7r7GivEg2xVrv5RuZZz32iY6saYALAQ6A+sAqYDQ621cyN+c584e043s9bOMsbUBmYCg4FhwGZr7UPOj6i+tfa2auxqTBAvslW5+kPlWj7R0jh7AYuttUuttXnAG8DpUbq3L6y1OdbaWc5xLjAPaI709yWn2UuIcJQ4ka3K1Tcq13KI1sDZHFgZ8n6VUxbTGGPaAIcB04Am1trgznBrgSbV1K1YI+5kq3KtFCrXctDFoTIwxmQAE4EbrLWh22piZX5D3RHiEJVrYhJtuUZr4FwNtAx538Ipi0mMMSmIEF611r7jFK9zu5L4JgAAAMhJREFU5lOC8yrrq6t/MUbcyFbl6guVazlEa+CcDmQbY7KMManAecD7Ubq3L4wxBngemGetHRlS9T5wiXN8CfBetPsWo8SFbFWuvlG5lnffaDnAG2MGAaOAAPCCtfaBqNzYJ8aYY4DvgNlAkVN8BzJv8hbQClgBDLHWbq6WTsYY8SBblat/VK7l3FcjhxRFUfyhi0OKoig+0YFTURTFJzpwKoqi+EQHTkVRFJ/owKkoiuITHTgVRVF8ogOnoiiKT3TgVBRF8cn/A/wW5690FwgaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# number = random.randint(0, train_x.shape[0])\n",
    "target = 1\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "number = 190\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "        \n",
    "        while(train_y[number] != target):\n",
    "            number +=1\n",
    "        col.imshow(train_x[number].reshape(28, 28))\n",
    "        print(number)\n",
    "        number += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to save images (Needed for the flow_from_directory function from ImageDataGenerator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_imgs(path:Path, data, labels):\n",
    "    for label in np.unique(labels):\n",
    "        (path/str(label)).mkdir(parents=True,exist_ok=True)\n",
    "    for i in range(len(data)):\n",
    "        if(len(labels)!=0):\n",
    "            imageio.imwrite( str( path/str(labels[i])/(str(i)+'.jpg') ), data[i].reshape(28,28,3))\n",
    "        else:\n",
    "            imageio.imwrite( str( path/(str(i)+'.jpg') ), data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipImage(image):\n",
    "    t = array_to_img(image.reshape(28,28,1), scale=True)\n",
    "    t = np.stack((t,)*3, axis=-1).astype(np.uint8)\n",
    "    t = tf.image.flip_left_right(np.array(t))\n",
    "    arr = np.array(img_to_array(t))\n",
    "    return arr.astype(np.uint8)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexValid = np.concatenate((np.where(train_y == 0)[0][200:], np.where(train_y == 1)[0][200:], np.where(train_y == 2)[0][200:], np.where(train_y == 3)[0][200:], np.where(train_y == 4)[0][200:], np.where(train_y == 5)[0][200:]))\n",
    "indexValid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200,)"
      ]
     },
     "execution_count": 872,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexTrain = np.concatenate((np.where(train_y == 0)[0][:200], np.where(train_y == 1)[0][:200], np.where(train_y == 2)[0][:200], np.where(train_y == 3)[0][:200], np.where(train_y == 4)[0][:200], np.where(train_y == 5)[0][:200]))\n",
    "indexTrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Validation labels encoding, doubled because we flip the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 6)"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit(train_y[indexValid].reshape(-1,1))\n",
    "yValid = enc.transform(train_y[indexValid].reshape(-1,1)).toarray()\n",
    "yValid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [],
   "source": [
    "yValid = np.concatenate((yValid, yValid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Labels Encoding. *(If needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 6)"
      ]
     },
     "execution_count": 876,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit(train_y[indexTrain].reshape(-1,1))\n",
    "yT = enc.transform(train_y[indexTrain].reshape(-1,1)).toarray()\n",
    "yT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [],
   "source": [
    "yT = np.concatenate((yT, yT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_size(image):\n",
    "    img = array_to_img(image, scale=True) #returns PIL Image\n",
    "    img = img.resize((128, 128)) #resize image\n",
    "    img = img.convert(mode='RGB') #makes 3 channels\n",
    "    arr = np.array(img_to_array(img)) #convert back to array\n",
    "    return arr.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation set Flipping and Resizing to fit the MobileNet Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [],
   "source": [
    "xV = train_x[indexValid]\n",
    "xValid = np.zeros((600,  128, 128 ,3))\n",
    "for i in range(300):\n",
    "    #xValid[i] = np.stack((xV[i].reshape(28,28),)*3, axis=-1)\n",
    "    xValid[i] = change_size(xV[i].reshape(28,28,1))\n",
    "for i in range(300):\n",
    "    t = flipImage(xV[i]).reshape(28,28,3)\n",
    "    xValid[i+300] = change_size(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same for training set. *(if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [],
   "source": [
    "xT = train_x[indexTrain]\n",
    "xTrain = np.zeros((2400,  28, 28 ,3))\n",
    "\n",
    "for i in range(1200):\n",
    "    xTrain[i] = np.stack((xT[i].reshape(28,28),)*3, axis=-1)\n",
    "    \n",
    "for i in range(1200):\n",
    "    t = flipImage(xT[i].reshape(28,28))\n",
    "    xTrain[i+1200] = t"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x181414c90>"
      ]
     },
     "execution_count": 881,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xValid[300] / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x180d39750>"
      ]
     },
     "execution_count": 882,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xValid[0]/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A bit ugly but it should be better for the preprocessing of the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 128, 128, 3)"
      ]
     },
     "execution_count": 883,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xValid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Training Data to directory if not already done.  Skip if otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Reshaping and saving training data to directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSplit = 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 784, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.stack((train_x,)*3, axis=-1).astype(np.uint8)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200,)"
      ]
     },
     "execution_count": 886,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexTrain = np.concatenate((np.where(train_y == 0)[0][:200], np.where(train_y == 1)[0][:200], np.where(train_y == 2)[0][:200], np.where(train_y == 3)[0][:200], np.where(train_y == 4)[0][:200], np.where(train_y == 5)[0][:200]))\n",
    "indexTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 784, 3)"
      ]
     },
     "execution_count": 887,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[indexTrain].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_imgs(Path('./train1200Classes/classes'), X_train[indexTrain], train_y[indexTrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 869,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexValid = np.concatenate((np.where(train_y == 0)[0][200:], np.where(train_y == 1)[0][200:], np.where(train_y == 2)[0][200:], np.where(train_y == 3)[0][200:], np.where(train_y == 4)[0][200:], np.where(train_y == 5)[0][200:]))\n",
    "indexValid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We should optimize buy having a fully balanced training_set, which the case now: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200. 200. 200. 200. 200. 200.]\n"
     ]
    }
   ],
   "source": [
    "t = train_y[indexTrain]\n",
    "count = np.zeros(6)\n",
    "for i in t:\n",
    "    count[i] += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Data, if we already have them on disc in the good format, you can skip part 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Not Needed if we already have them on disc with the call (np.load('test128RGB.npy')).\n",
    "test_ds = np.load('test.npz')\n",
    "test_x = test_ds['arr_0']\n",
    "\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_size(image):\n",
    "    img = array_to_img(image, scale=True) #returns PIL Image\n",
    "    img = img.resize((128, 128)) #resize image\n",
    "    img = img.convert(mode='RGB') #makes 3 channels\n",
    "    arr = np.array(img_to_array(img)) #convert back to array\n",
    "    return arr.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resizing the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.stack((train_x,)*3, axis=-1).astype(np.uint8)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 %\n",
      "2 %\n",
      "3 %\n",
      "4 %\n",
      "5 %\n",
      "6 %\n",
      "7 %\n",
      "8 %\n",
      "9 %\n",
      "10 %\n",
      "11 %\n",
      "12 %\n",
      "13 %\n",
      "14 %\n",
      "15 %\n",
      "16 %\n",
      "17 %\n",
      "18 %\n",
      "19 %\n",
      "20 %\n",
      "21 %\n",
      "22 %\n",
      "23 %\n",
      "24 %\n",
      "25 %\n",
      "26 %\n",
      "27 %\n",
      "28 %\n",
      "29 %\n",
      "30 %\n",
      "31 %\n",
      "32 %\n",
      "33 %\n",
      "34 %\n",
      "35 %\n",
      "36 %\n",
      "37 %\n",
      "38 %\n",
      "39 %\n",
      "40 %\n",
      "41 %\n",
      "42 %\n",
      "43 %\n",
      "44 %\n",
      "45 %\n",
      "46 %\n",
      "47 %\n",
      "48 %\n",
      "49 %\n",
      "50 %\n",
      "51 %\n",
      "52 %\n",
      "53 %\n",
      "54 %\n",
      "55 %\n",
      "56 %\n",
      "57 %\n",
      "58 %\n",
      "59 %\n",
      "60 %\n",
      "61 %\n",
      "62 %\n",
      "63 %\n",
      "64 %\n",
      "65 %\n",
      "66 %\n",
      "67 %\n",
      "68 %\n",
      "69 %\n",
      "70 %\n",
      "71 %\n",
      "72 %\n",
      "73 %\n",
      "74 %\n",
      "75 %\n",
      "76 %\n",
      "77 %\n",
      "78 %\n",
      "79 %\n",
      "80 %\n",
      "81 %\n",
      "82 %\n",
      "83 %\n",
      "84 %\n",
      "85 %\n",
      "86 %\n",
      "87 %\n",
      "88 %\n",
      "89 %\n",
      "90 %\n",
      "91 %\n",
      "92 %\n",
      "93 %\n",
      "94 %\n",
      "95 %\n",
      "96 %\n",
      "97 %\n",
      "98 %\n",
      "99 %\n",
      "100 %\n"
     ]
    }
   ],
   "source": [
    "testReshapedX = np.zeros((test_x.shape[0], 128,  128, 3))\n",
    "X_test = np.stack((test_x,)*3, axis=-1).astype(np.uint8)\n",
    "percentage =  60000 /100\n",
    "p = 1\n",
    "for i in range(X_test.shape[0]):\n",
    "    testReshapedX[i] = change_size(X_test[i].reshape(28,28,3))\n",
    "    if i % percentage == 0:\n",
    "        print(p, \"%\")\n",
    "        p +=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving  the data in case of crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"test128RGB.npy\", testReshapedX.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testReshapedX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 128, 128, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Cannot be done if not on disc. (Should load them from the above call).\n",
    "testReshapedX = np.load('test128RGB.npy')\n",
    "testReshapedX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x166461550>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(testReshapedX[30000] /255)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNet Transfer Modle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepocess the validation set. * I often made mistakes because of that haha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [],
   "source": [
    "xValid = keras.applications.mobilenet.preprocess_input(xValid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 897,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xValid[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 128, 128, 3)"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xValid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17e139590>"
      ]
     },
     "execution_count": 788,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xValid[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Image Generator, from the directory created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import MobileNet, MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1200 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import preprocess_input\n",
    "import tensorflow as tf\n",
    "\n",
    "train_datagen=tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input, horizontal_flip=True, width_shift_range=0.17, zoom_range=0.1,\n",
    "    height_shift_range=0.17, shear_range=0.01, rotation_range=25, fill_mode=\"constant\", validation_split=0.00)\n",
    "train_generator = train_datagen.flow_from_directory('./train1200Classes/classes', class_mode='categorical', target_size=(128,128), subset='training')\n",
    "#valid_generator = train_datagen.flow_from_directory('./train1200A/classes', class_mode='categorical', target_size=(128,128), subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 128, 3)\n",
      "(32, 6)\n"
     ]
    }
   ],
   "source": [
    "## Checking\n",
    "x, y = train_generator[0]\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 891,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[22].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17da670d0>"
      ]
     },
     "execution_count": 899,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 128, 128, 3)"
      ]
     },
     "execution_count": 814,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model, not sure whether to freeze the upper model. Currently, don't think we should."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(MobileNet(input_shape=(128,128, 3),  include_top = False, pooling = 'avg', weights = 'imagenet'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(6, activation = 'softmax'))\n",
    "\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenet_1.00_128 (Function (None, 1024)              3228864   \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 3,360,838\n",
      "Trainable params: 131,974\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfreeze the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable = True\n",
    "model.layers[0].trainable = True\n",
    "model.layers[1].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenet_1.00_128 (Function (None, 1024)              3228864   \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 3,360,838\n",
      "Trainable params: 3,338,950\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile with very small learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "38/38 [==============================] - 51s 1s/step - loss: 3.0965 - accuracy: 0.1725 - val_loss: 2.5192 - val_accuracy: 0.2133\n",
      "Epoch 2/1000\n",
      "38/38 [==============================] - 45s 1s/step - loss: 2.6424 - accuracy: 0.2033 - val_loss: 2.1494 - val_accuracy: 0.2067\n",
      "Epoch 3/1000\n",
      "38/38 [==============================] - 45s 1s/step - loss: 2.3856 - accuracy: 0.2283 - val_loss: 1.8849 - val_accuracy: 0.2283\n",
      "Epoch 4/1000\n",
      "38/38 [==============================] - 45s 1s/step - loss: 2.0986 - accuracy: 0.2650 - val_loss: 1.7334 - val_accuracy: 0.2950\n",
      "Epoch 5/1000\n",
      "38/38 [==============================] - 45s 1s/step - loss: 1.8733 - accuracy: 0.3167 - val_loss: 1.6675 - val_accuracy: 0.3483\n",
      "Epoch 6/1000\n",
      "38/38 [==============================] - 55s 1s/step - loss: 1.7762 - accuracy: 0.3492 - val_loss: 1.6131 - val_accuracy: 0.3567\n",
      "Epoch 7/1000\n",
      "38/38 [==============================] - 48s 1s/step - loss: 1.7431 - accuracy: 0.3742 - val_loss: 1.5699 - val_accuracy: 0.3733\n",
      "Epoch 8/1000\n",
      "38/38 [==============================] - 47s 1s/step - loss: 1.6105 - accuracy: 0.3892 - val_loss: 1.5466 - val_accuracy: 0.3967\n",
      "Epoch 9/1000\n",
      "38/38 [==============================] - 47s 1s/step - loss: 1.6079 - accuracy: 0.4108 - val_loss: 1.4891 - val_accuracy: 0.4233\n",
      "Epoch 10/1000\n",
      "38/38 [==============================] - 46s 1s/step - loss: 1.4939 - accuracy: 0.4458 - val_loss: 1.4864 - val_accuracy: 0.4283\n",
      "Epoch 11/1000\n",
      "38/38 [==============================] - 46s 1s/step - loss: 1.4768 - accuracy: 0.4592 - val_loss: 1.4476 - val_accuracy: 0.4467\n",
      "Epoch 12/1000\n",
      "38/38 [==============================] - 45s 1s/step - loss: 1.4829 - accuracy: 0.4525 - val_loss: 1.4111 - val_accuracy: 0.4600\n",
      "Epoch 13/1000\n",
      "38/38 [==============================] - 46s 1s/step - loss: 1.4155 - accuracy: 0.4658 - val_loss: 1.3573 - val_accuracy: 0.4833\n",
      "Epoch 14/1000\n",
      "38/38 [==============================] - 46s 1s/step - loss: 1.2874 - accuracy: 0.5283 - val_loss: 1.2855 - val_accuracy: 0.5117\n",
      "Epoch 15/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 1.3175 - accuracy: 0.5158 - val_loss: 1.2207 - val_accuracy: 0.5300\n",
      "Epoch 16/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 1.2382 - accuracy: 0.5425 - val_loss: 1.1794 - val_accuracy: 0.5183\n",
      "Epoch 17/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 1.2636 - accuracy: 0.5317 - val_loss: 1.1427 - val_accuracy: 0.5567\n",
      "Epoch 18/1000\n",
      "38/38 [==============================] - 42s 1s/step - loss: 1.2431 - accuracy: 0.5475 - val_loss: 1.1044 - val_accuracy: 0.5883\n",
      "Epoch 19/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 1.1461 - accuracy: 0.5742 - val_loss: 1.0873 - val_accuracy: 0.5933\n",
      "Epoch 20/1000\n",
      "38/38 [==============================] - 42s 1s/step - loss: 1.1493 - accuracy: 0.5667 - val_loss: 1.0640 - val_accuracy: 0.6117\n",
      "Epoch 21/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 1.1259 - accuracy: 0.5850 - val_loss: 1.0450 - val_accuracy: 0.6167\n",
      "Epoch 22/1000\n",
      "38/38 [==============================] - 44s 1s/step - loss: 1.0867 - accuracy: 0.6067 - val_loss: 0.9888 - val_accuracy: 0.6450\n",
      "Epoch 23/1000\n",
      "38/38 [==============================] - 44s 1s/step - loss: 1.1082 - accuracy: 0.5892 - val_loss: 0.9822 - val_accuracy: 0.6483\n",
      "Epoch 24/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 1.0925 - accuracy: 0.6117 - val_loss: 0.9590 - val_accuracy: 0.6433\n",
      "Epoch 25/1000\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.9836 - accuracy: 0.6325 - val_loss: 1.0017 - val_accuracy: 0.6250\n",
      "Epoch 26/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 1.0446 - accuracy: 0.6233 - val_loss: 0.9857 - val_accuracy: 0.6250\n",
      "Epoch 27/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.9924 - accuracy: 0.6233 - val_loss: 0.9710 - val_accuracy: 0.6433\n",
      "Epoch 28/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.9536 - accuracy: 0.6667 - val_loss: 0.9478 - val_accuracy: 0.6533\n",
      "Epoch 29/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.9654 - accuracy: 0.6575 - val_loss: 0.9398 - val_accuracy: 0.6600\n",
      "Epoch 30/1000\n",
      "38/38 [==============================] - 39s 1s/step - loss: 0.9522 - accuracy: 0.6617 - val_loss: 0.9014 - val_accuracy: 0.6667\n",
      "Epoch 31/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.9213 - accuracy: 0.6658 - val_loss: 0.8799 - val_accuracy: 0.6767\n",
      "Epoch 32/1000\n",
      "38/38 [==============================] - 39s 1s/step - loss: 0.8978 - accuracy: 0.6625 - val_loss: 0.8431 - val_accuracy: 0.6983\n",
      "Epoch 33/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.9081 - accuracy: 0.6842 - val_loss: 0.8382 - val_accuracy: 0.7033\n",
      "Epoch 34/1000\n",
      "38/38 [==============================] - 39s 1s/step - loss: 0.8923 - accuracy: 0.6725 - val_loss: 0.8190 - val_accuracy: 0.7100\n",
      "Epoch 35/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.8949 - accuracy: 0.6842 - val_loss: 0.8008 - val_accuracy: 0.7150\n",
      "Epoch 36/1000\n",
      "38/38 [==============================] - 39s 1s/step - loss: 0.8679 - accuracy: 0.6800 - val_loss: 0.7719 - val_accuracy: 0.7333\n",
      "Epoch 37/1000\n",
      "38/38 [==============================] - 39s 1s/step - loss: 0.8369 - accuracy: 0.7008 - val_loss: 0.7661 - val_accuracy: 0.7417\n",
      "Epoch 38/1000\n",
      "38/38 [==============================] - 39s 1s/step - loss: 0.8449 - accuracy: 0.7008 - val_loss: 0.7405 - val_accuracy: 0.7617\n",
      "Epoch 39/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.8335 - accuracy: 0.7017 - val_loss: 0.7306 - val_accuracy: 0.7533\n",
      "Epoch 40/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.7881 - accuracy: 0.7250 - val_loss: 0.7382 - val_accuracy: 0.7517\n",
      "Epoch 41/1000\n",
      "38/38 [==============================] - 54s 1s/step - loss: 0.8113 - accuracy: 0.7100 - val_loss: 0.7221 - val_accuracy: 0.7667\n",
      "Epoch 42/1000\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.8100 - accuracy: 0.7125 - val_loss: 0.7626 - val_accuracy: 0.7350\n",
      "Epoch 43/1000\n",
      "38/38 [==============================] - 49s 1s/step - loss: 0.7753 - accuracy: 0.7250 - val_loss: 0.7116 - val_accuracy: 0.7617\n",
      "Epoch 44/1000\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.7600 - accuracy: 0.7350 - val_loss: 0.7039 - val_accuracy: 0.7633\n",
      "Epoch 45/1000\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.7241 - accuracy: 0.7350 - val_loss: 0.6895 - val_accuracy: 0.7783\n",
      "Epoch 46/1000\n",
      "38/38 [==============================] - 47s 1s/step - loss: 0.7753 - accuracy: 0.7142 - val_loss: 0.6889 - val_accuracy: 0.7683\n",
      "Epoch 47/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.7747 - accuracy: 0.7375 - val_loss: 0.6792 - val_accuracy: 0.7683\n",
      "Epoch 48/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.7537 - accuracy: 0.7400 - val_loss: 0.7217 - val_accuracy: 0.7500\n",
      "Epoch 49/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.7401 - accuracy: 0.7292 - val_loss: 0.6713 - val_accuracy: 0.7833\n",
      "Epoch 50/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.6928 - accuracy: 0.7425 - val_loss: 0.6768 - val_accuracy: 0.7833\n",
      "Epoch 51/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.6963 - accuracy: 0.7500 - val_loss: 0.6970 - val_accuracy: 0.7683\n",
      "Epoch 52/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.7342 - accuracy: 0.7408 - val_loss: 0.6546 - val_accuracy: 0.7883\n",
      "Epoch 53/1000\n",
      "38/38 [==============================] - 39s 1s/step - loss: 0.7291 - accuracy: 0.7483 - val_loss: 0.6389 - val_accuracy: 0.7950\n",
      "Epoch 54/1000\n",
      "38/38 [==============================] - 39s 1s/step - loss: 0.7172 - accuracy: 0.7417 - val_loss: 0.6366 - val_accuracy: 0.7883\n",
      "Epoch 55/1000\n",
      "38/38 [==============================] - 39s 1s/step - loss: 0.6410 - accuracy: 0.7767 - val_loss: 0.6088 - val_accuracy: 0.7950\n",
      "Epoch 56/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.6581 - accuracy: 0.7608 - val_loss: 0.6040 - val_accuracy: 0.7950\n",
      "Epoch 57/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.6868 - accuracy: 0.7483 - val_loss: 0.5924 - val_accuracy: 0.8033\n",
      "Epoch 58/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.6806 - accuracy: 0.7575 - val_loss: 0.6010 - val_accuracy: 0.8017\n",
      "Epoch 59/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.6294 - accuracy: 0.7808 - val_loss: 0.5919 - val_accuracy: 0.8100\n",
      "Epoch 60/1000\n",
      "38/38 [==============================] - 39s 1s/step - loss: 0.6569 - accuracy: 0.7725 - val_loss: 0.5773 - val_accuracy: 0.8100\n",
      "Epoch 61/1000\n",
      "38/38 [==============================] - 39s 1s/step - loss: 0.6151 - accuracy: 0.7958 - val_loss: 0.5739 - val_accuracy: 0.8133\n",
      "Epoch 62/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.6353 - accuracy: 0.7800 - val_loss: 0.5702 - val_accuracy: 0.8183\n",
      "Epoch 63/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.6238 - accuracy: 0.7750 - val_loss: 0.5602 - val_accuracy: 0.8250\n",
      "Epoch 64/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.6303 - accuracy: 0.7792 - val_loss: 0.5900 - val_accuracy: 0.8117\n",
      "Epoch 65/1000\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.6351 - accuracy: 0.7842 - val_loss: 0.5608 - val_accuracy: 0.8233\n",
      "Epoch 66/1000\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.6283 - accuracy: 0.7558 - val_loss: 0.5566 - val_accuracy: 0.8250\n",
      "Epoch 67/1000\n",
      "38/38 [==============================] - 48s 1s/step - loss: 0.5471 - accuracy: 0.8142 - val_loss: 0.5556 - val_accuracy: 0.8183\n",
      "Epoch 68/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.6133 - accuracy: 0.7783 - val_loss: 0.5597 - val_accuracy: 0.8250\n",
      "Epoch 69/1000\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.5958 - accuracy: 0.7825 - val_loss: 0.5540 - val_accuracy: 0.8167\n",
      "Epoch 70/1000\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.5542 - accuracy: 0.8083 - val_loss: 0.5546 - val_accuracy: 0.8200\n",
      "Epoch 71/1000\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.5793 - accuracy: 0.7867 - val_loss: 0.5554 - val_accuracy: 0.8283\n",
      "Epoch 72/1000\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.5542 - accuracy: 0.7942 - val_loss: 0.5463 - val_accuracy: 0.8283\n",
      "Epoch 73/1000\n",
      "38/38 [==============================] - 46s 1s/step - loss: 0.5605 - accuracy: 0.7942 - val_loss: 0.5377 - val_accuracy: 0.8333\n",
      "Epoch 74/1000\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.5684 - accuracy: 0.7917 - val_loss: 0.5844 - val_accuracy: 0.8183\n",
      "Epoch 75/1000\n",
      "38/38 [==============================] - 46s 1s/step - loss: 0.5442 - accuracy: 0.8050 - val_loss: 0.5345 - val_accuracy: 0.8383\n",
      "Epoch 76/1000\n",
      "38/38 [==============================] - 47s 1s/step - loss: 0.5697 - accuracy: 0.7942 - val_loss: 0.5479 - val_accuracy: 0.8300\n",
      "Epoch 77/1000\n",
      "38/38 [==============================] - 48s 1s/step - loss: 0.5632 - accuracy: 0.8008 - val_loss: 0.5318 - val_accuracy: 0.8433\n",
      "Epoch 78/1000\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.5459 - accuracy: 0.8083 - val_loss: 0.5470 - val_accuracy: 0.8333\n",
      "Epoch 79/1000\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.5413 - accuracy: 0.8108 - val_loss: 0.5411 - val_accuracy: 0.8350\n",
      "Epoch 80/1000\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.5517 - accuracy: 0.7967 - val_loss: 0.5223 - val_accuracy: 0.8350\n",
      "Epoch 81/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.5290 - accuracy: 0.8000 - val_loss: 0.5175 - val_accuracy: 0.8367\n",
      "Epoch 82/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.5070 - accuracy: 0.8167 - val_loss: 0.5253 - val_accuracy: 0.8433\n",
      "Epoch 83/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.5139 - accuracy: 0.8150 - val_loss: 0.5147 - val_accuracy: 0.8417\n",
      "Epoch 84/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.5256 - accuracy: 0.8100 - val_loss: 0.5015 - val_accuracy: 0.8417\n",
      "Epoch 85/1000\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.5460 - accuracy: 0.8008 - val_loss: 0.5044 - val_accuracy: 0.8383\n",
      "Epoch 86/1000\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.5200 - accuracy: 0.8125 - val_loss: 0.5080 - val_accuracy: 0.8433\n",
      "Epoch 87/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.5180 - accuracy: 0.8158 - val_loss: 0.5069 - val_accuracy: 0.8317\n",
      "Epoch 88/1000\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.5188 - accuracy: 0.8142 - val_loss: 0.4937 - val_accuracy: 0.8367\n",
      "Epoch 89/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.4882 - accuracy: 0.8292 - val_loss: 0.4883 - val_accuracy: 0.8400\n",
      "Epoch 90/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.4627 - accuracy: 0.8358 - val_loss: 0.4981 - val_accuracy: 0.8383\n",
      "Epoch 91/1000\n",
      "38/38 [==============================] - 47s 1s/step - loss: 0.4919 - accuracy: 0.8142 - val_loss: 0.4915 - val_accuracy: 0.8350\n",
      "Epoch 92/1000\n",
      "38/38 [==============================] - 46s 1s/step - loss: 0.5048 - accuracy: 0.8117 - val_loss: 0.4828 - val_accuracy: 0.8400\n",
      "Epoch 93/1000\n",
      "38/38 [==============================] - 47s 1s/step - loss: 0.4456 - accuracy: 0.8467 - val_loss: 0.4830 - val_accuracy: 0.8450\n",
      "Epoch 94/1000\n",
      "38/38 [==============================] - 46s 1s/step - loss: 0.4748 - accuracy: 0.8292 - val_loss: 0.4851 - val_accuracy: 0.8400\n",
      "Epoch 95/1000\n",
      "38/38 [==============================] - 50s 1s/step - loss: 0.4818 - accuracy: 0.8233 - val_loss: 0.4757 - val_accuracy: 0.8450\n",
      "Epoch 96/1000\n",
      "38/38 [==============================] - 47s 1s/step - loss: 0.4380 - accuracy: 0.8408 - val_loss: 0.4712 - val_accuracy: 0.8467\n",
      "Epoch 97/1000\n",
      "38/38 [==============================] - 47s 1s/step - loss: 0.4310 - accuracy: 0.8467 - val_loss: 0.4680 - val_accuracy: 0.8467\n",
      "Epoch 98/1000\n",
      "38/38 [==============================] - 50s 1s/step - loss: 0.4336 - accuracy: 0.8425 - val_loss: 0.4618 - val_accuracy: 0.8500\n",
      "Epoch 99/1000\n",
      "38/38 [==============================] - 49s 1s/step - loss: 0.4576 - accuracy: 0.8367 - val_loss: 0.4700 - val_accuracy: 0.8450\n",
      "Epoch 100/1000\n",
      "38/38 [==============================] - 46s 1s/step - loss: 0.4602 - accuracy: 0.8300 - val_loss: 0.5090 - val_accuracy: 0.8433\n",
      "Epoch 101/1000\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.4297 - accuracy: 0.8475 - val_loss: 0.4851 - val_accuracy: 0.8467\n",
      "Epoch 102/1000\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.4529 - accuracy: 0.8392 - val_loss: 0.4950 - val_accuracy: 0.8483\n",
      "Epoch 103/1000\n",
      "38/38 [==============================] - 47s 1s/step - loss: 0.4507 - accuracy: 0.8367 - val_loss: 0.4883 - val_accuracy: 0.8550\n",
      "Epoch 104/1000\n",
      "38/38 [==============================] - 51s 1s/step - loss: 0.4391 - accuracy: 0.8317 - val_loss: 0.4871 - val_accuracy: 0.8550\n",
      "Epoch 105/1000\n",
      "38/38 [==============================] - 47s 1s/step - loss: 0.4307 - accuracy: 0.8408 - val_loss: 0.4844 - val_accuracy: 0.8533\n",
      "Epoch 106/1000\n",
      "38/38 [==============================] - 57s 1s/step - loss: 0.4291 - accuracy: 0.8392 - val_loss: 0.4661 - val_accuracy: 0.8517\n",
      "Epoch 107/1000\n",
      "38/38 [==============================] - 58s 2s/step - loss: 0.4387 - accuracy: 0.8550 - val_loss: 0.4564 - val_accuracy: 0.8533\n",
      "Epoch 108/1000\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.4204 - accuracy: 0.8517 - val_loss: 0.4551 - val_accuracy: 0.8517\n",
      "Epoch 109/1000\n",
      "38/38 [==============================] - 47s 1s/step - loss: 0.4341 - accuracy: 0.8408 - val_loss: 0.4513 - val_accuracy: 0.8583\n",
      "Epoch 110/1000\n",
      "38/38 [==============================] - 47s 1s/step - loss: 0.4447 - accuracy: 0.8317 - val_loss: 0.4703 - val_accuracy: 0.8550\n",
      "Epoch 111/1000\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.4114 - accuracy: 0.8567 - val_loss: 0.4521 - val_accuracy: 0.8600\n",
      "Epoch 112/1000\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.4137 - accuracy: 0.8508 - val_loss: 0.4575 - val_accuracy: 0.8633\n",
      "Epoch 113/1000\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.3745 - accuracy: 0.8567 - val_loss: 0.4529 - val_accuracy: 0.8617\n",
      "Epoch 114/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.3848 - accuracy: 0.8633 - val_loss: 0.4655 - val_accuracy: 0.8500\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 41s 1s/step - loss: 0.3809 - accuracy: 0.8642 - val_loss: 0.4589 - val_accuracy: 0.8550\n",
      "Epoch 116/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.3783 - accuracy: 0.8675 - val_loss: 0.4653 - val_accuracy: 0.8583\n",
      "Epoch 117/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.3967 - accuracy: 0.8600 - val_loss: 0.4533 - val_accuracy: 0.8533\n",
      "Epoch 118/1000\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.3751 - accuracy: 0.8692 - val_loss: 0.4532 - val_accuracy: 0.8533\n",
      "Epoch 119/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.3940 - accuracy: 0.8483 - val_loss: 0.4567 - val_accuracy: 0.8567\n",
      "Epoch 120/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.3635 - accuracy: 0.8675 - val_loss: 0.4489 - val_accuracy: 0.8600\n",
      "Epoch 121/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.3706 - accuracy: 0.8683 - val_loss: 0.4462 - val_accuracy: 0.8617\n",
      "Epoch 122/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.3829 - accuracy: 0.8600 - val_loss: 0.4350 - val_accuracy: 0.8667\n",
      "Epoch 123/1000\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.3711 - accuracy: 0.8692 - val_loss: 0.4390 - val_accuracy: 0.8650\n",
      "Epoch 124/1000\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.3646 - accuracy: 0.8608 - val_loss: 0.4395 - val_accuracy: 0.8700\n",
      "Epoch 125/1000\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.3648 - accuracy: 0.8650 - val_loss: 0.4490 - val_accuracy: 0.8683\n",
      "Epoch 126/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.3419 - accuracy: 0.8600 - val_loss: 0.4351 - val_accuracy: 0.8683\n",
      "Epoch 127/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.3641 - accuracy: 0.8625 - val_loss: 0.4557 - val_accuracy: 0.8683\n",
      "Epoch 128/1000\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.3747 - accuracy: 0.8700 - val_loss: 0.4525 - val_accuracy: 0.8700\n",
      "Epoch 129/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.3439 - accuracy: 0.8858 - val_loss: 0.4387 - val_accuracy: 0.8700\n",
      "Epoch 130/1000\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.3333 - accuracy: 0.8800 - val_loss: 0.4321 - val_accuracy: 0.8650\n",
      "Epoch 131/1000\n",
      "38/38 [==============================] - 46s 1s/step - loss: 0.3333 - accuracy: 0.8783 - val_loss: 0.4295 - val_accuracy: 0.8667\n",
      "Epoch 132/1000\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.3537 - accuracy: 0.8792 - val_loss: 0.4257 - val_accuracy: 0.8683\n",
      "Epoch 133/1000\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.3585 - accuracy: 0.8775 - val_loss: 0.4219 - val_accuracy: 0.8717\n",
      "Epoch 134/1000\n",
      "38/38 [==============================] - 48s 1s/step - loss: 0.3311 - accuracy: 0.8783 - val_loss: 0.4161 - val_accuracy: 0.8750\n",
      "Epoch 135/1000\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.3318 - accuracy: 0.8775 - val_loss: 0.4168 - val_accuracy: 0.8700\n",
      "Epoch 136/1000\n",
      "38/38 [==============================] - 51s 1s/step - loss: 0.3236 - accuracy: 0.8767 - val_loss: 0.4198 - val_accuracy: 0.8733\n",
      "Epoch 137/1000\n",
      "38/38 [==============================] - 50s 1s/step - loss: 0.3157 - accuracy: 0.8842 - val_loss: 0.4188 - val_accuracy: 0.8800\n",
      "Epoch 138/1000\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.3623 - accuracy: 0.8692 - val_loss: 0.4108 - val_accuracy: 0.8817\n",
      "Epoch 139/1000\n",
      "38/38 [==============================] - 47s 1s/step - loss: 0.3496 - accuracy: 0.8708 - val_loss: 0.4054 - val_accuracy: 0.8883\n",
      "Epoch 140/1000\n",
      "38/38 [==============================] - 47s 1s/step - loss: 0.2916 - accuracy: 0.8883 - val_loss: 0.4064 - val_accuracy: 0.8800\n",
      "Epoch 141/1000\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.2982 - accuracy: 0.9017 - val_loss: 0.4032 - val_accuracy: 0.8867\n",
      "Epoch 142/1000\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.3475 - accuracy: 0.8633 - val_loss: 0.4129 - val_accuracy: 0.8833\n",
      "Epoch 143/1000\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.2888 - accuracy: 0.8975 - val_loss: 0.4200 - val_accuracy: 0.8767\n",
      "Epoch 144/1000\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.3117 - accuracy: 0.8842 - val_loss: 0.4118 - val_accuracy: 0.8800\n",
      "Epoch 145/1000\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.2914 - accuracy: 0.8883 - val_loss: 0.4167 - val_accuracy: 0.8783\n",
      "Epoch 146/1000\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.2815 - accuracy: 0.8942 - val_loss: 0.4187 - val_accuracy: 0.8783\n",
      "Epoch 147/1000\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.3044 - accuracy: 0.8925 - val_loss: 0.4241 - val_accuracy: 0.8783\n",
      "Epoch 148/1000\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.2900 - accuracy: 0.8983 - val_loss: 0.4273 - val_accuracy: 0.8783\n",
      "Epoch 149/1000\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.2672 - accuracy: 0.9050 - val_loss: 0.4359 - val_accuracy: 0.8750\n",
      "Epoch 150/1000\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.2733 - accuracy: 0.9042 - val_loss: 0.4322 - val_accuracy: 0.8733\n",
      "Epoch 151/1000\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.2638 - accuracy: 0.8967 - val_loss: 0.4202 - val_accuracy: 0.8733\n",
      "Epoch 152/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.2751 - accuracy: 0.9050 - val_loss: 0.4089 - val_accuracy: 0.8800\n",
      "Epoch 153/1000\n",
      "38/38 [==============================] - 48s 1s/step - loss: 0.3017 - accuracy: 0.8908 - val_loss: 0.3990 - val_accuracy: 0.8833\n",
      "Epoch 154/1000\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.2589 - accuracy: 0.9033 - val_loss: 0.3986 - val_accuracy: 0.8867\n",
      "Epoch 155/1000\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.2618 - accuracy: 0.8983 - val_loss: 0.4012 - val_accuracy: 0.8817\n",
      "Epoch 156/1000\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.2506 - accuracy: 0.9067 - val_loss: 0.4046 - val_accuracy: 0.8817\n",
      "Epoch 157/1000\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.3102 - accuracy: 0.8767 - val_loss: 0.4021 - val_accuracy: 0.8800\n",
      "Epoch 158/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.2419 - accuracy: 0.9142 - val_loss: 0.4020 - val_accuracy: 0.8817\n",
      "Epoch 159/1000\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.2272 - accuracy: 0.9250 - val_loss: 0.3976 - val_accuracy: 0.8867\n",
      "Epoch 160/1000\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.2959 - accuracy: 0.8925 - val_loss: 0.3920 - val_accuracy: 0.8867\n",
      "Epoch 161/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.2347 - accuracy: 0.9167 - val_loss: 0.3977 - val_accuracy: 0.8817\n",
      "Epoch 162/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.2631 - accuracy: 0.8925 - val_loss: 0.3877 - val_accuracy: 0.8883\n",
      "Epoch 163/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.2599 - accuracy: 0.8958 - val_loss: 0.3918 - val_accuracy: 0.8883\n",
      "Epoch 164/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.2795 - accuracy: 0.8942 - val_loss: 0.3945 - val_accuracy: 0.8883\n",
      "Epoch 165/1000\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.2643 - accuracy: 0.9025 - val_loss: 0.3964 - val_accuracy: 0.8850\n",
      "Epoch 166/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.2486 - accuracy: 0.9092 - val_loss: 0.3965 - val_accuracy: 0.8750\n",
      "Epoch 167/1000\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.2306 - accuracy: 0.9150 - val_loss: 0.3974 - val_accuracy: 0.8750\n",
      "Epoch 168/1000\n",
      "38/38 [==============================] - 51s 1s/step - loss: 0.2202 - accuracy: 0.9183 - val_loss: 0.4053 - val_accuracy: 0.8733\n",
      "Epoch 169/1000\n",
      "38/38 [==============================] - 52s 1s/step - loss: 0.2500 - accuracy: 0.9117 - val_loss: 0.4070 - val_accuracy: 0.8733\n",
      "Epoch 170/1000\n",
      "38/38 [==============================] - 51s 1s/step - loss: 0.2329 - accuracy: 0.9192 - val_loss: 0.4242 - val_accuracy: 0.8733\n",
      "Epoch 171/1000\n",
      "38/38 [==============================] - 49s 1s/step - loss: 0.2439 - accuracy: 0.8992 - val_loss: 0.4041 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "38/38 [==============================] - 49s 1s/step - loss: 0.2234 - accuracy: 0.9200 - val_loss: 0.3998 - val_accuracy: 0.8850\n",
      "Epoch 173/1000\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.2748 - accuracy: 0.9000 - val_loss: 0.3973 - val_accuracy: 0.8883\n",
      "Epoch 174/1000\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.2324 - accuracy: 0.9225 - val_loss: 0.3955 - val_accuracy: 0.8850\n",
      "Epoch 175/1000\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.2316 - accuracy: 0.9208 - val_loss: 0.3914 - val_accuracy: 0.8850\n",
      "Epoch 176/1000\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.2093 - accuracy: 0.9292 - val_loss: 0.3891 - val_accuracy: 0.8850\n",
      "Epoch 177/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.2261 - accuracy: 0.9267 - val_loss: 0.3883 - val_accuracy: 0.8883\n",
      "Epoch 178/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.2605 - accuracy: 0.9058 - val_loss: 0.4044 - val_accuracy: 0.8767\n",
      "Epoch 179/1000\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.2167 - accuracy: 0.9183 - val_loss: 0.4512 - val_accuracy: 0.8683\n",
      "Epoch 180/1000\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.2351 - accuracy: 0.9208 - val_loss: 0.4413 - val_accuracy: 0.8683\n",
      "Epoch 181/1000\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.1992 - accuracy: 0.9275 - val_loss: 0.4249 - val_accuracy: 0.8733\n",
      "Epoch 182/1000\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.1983 - accuracy: 0.9283 - val_loss: 0.3994 - val_accuracy: 0.8767\n",
      "Epoch 183/1000\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.2006 - accuracy: 0.9367 - val_loss: 0.4064 - val_accuracy: 0.8767\n",
      "Epoch 184/1000\n",
      "38/38 [==============================] - 51s 1s/step - loss: 0.2106 - accuracy: 0.9233 - val_loss: 0.3962 - val_accuracy: 0.8833\n",
      "Epoch 185/1000\n",
      "38/38 [==============================] - 50s 1s/step - loss: 0.2118 - accuracy: 0.9192 - val_loss: 0.3987 - val_accuracy: 0.8900\n",
      "Epoch 186/1000\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.2298 - accuracy: 0.9158 - val_loss: 0.4007 - val_accuracy: 0.8917\n",
      "Epoch 187/1000\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.1992 - accuracy: 0.9250 - val_loss: 0.3940 - val_accuracy: 0.8867\n",
      "Epoch 188/1000\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.2103 - accuracy: 0.9183 - val_loss: 0.3889 - val_accuracy: 0.8933\n",
      "Epoch 189/1000\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.1910 - accuracy: 0.9342 - val_loss: 0.3933 - val_accuracy: 0.8900\n",
      "Epoch 190/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.1843 - accuracy: 0.9383 - val_loss: 0.3958 - val_accuracy: 0.8817\n",
      "Epoch 191/1000\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.1575 - accuracy: 0.9375 - val_loss: 0.4118 - val_accuracy: 0.8733\n",
      "Epoch 192/1000\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.2095 - accuracy: 0.9275 - val_loss: 0.4122 - val_accuracy: 0.8767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x182d77bd0>"
      ]
     },
     "execution_count": 925,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "model.fit_generator(generator=train_generator,epochs=1000,validation_data=(xValid , yValid), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1200 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_datagen=tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input, horizontal_flip=True, width_shift_range=0.17, zoom_range=0.1,\n",
    "    height_shift_range=0.18, shear_range=0.01, rotation_range=35, fill_mode=\"constant\", validation_split=0.00)\n",
    "train_generator2 = train_datagen.flow_from_directory('./train1200Classes/classes', class_mode='categorical', target_size=(128,128), subset='training')\n",
    "#valid_generator = train_datagen.flow_from_directory('./train1200A/classes', class_mode='categorical', target_size=(128,128), subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "38/38 [==============================] - 48s 1s/step - loss: 0.3153 - accuracy: 0.8900 - val_loss: 0.3824 - val_accuracy: 0.8850\n",
      "Epoch 2/1000\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.2891 - accuracy: 0.9008 - val_loss: 0.3864 - val_accuracy: 0.8900\n",
      "Epoch 3/1000\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.3134 - accuracy: 0.8858 - val_loss: 0.3940 - val_accuracy: 0.8850\n",
      "Epoch 4/1000\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.3397 - accuracy: 0.8675 - val_loss: 0.3990 - val_accuracy: 0.8817\n",
      "Epoch 5/1000\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.2874 - accuracy: 0.8958 - val_loss: 0.4040 - val_accuracy: 0.8783\n",
      "Epoch 6/1000\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.2818 - accuracy: 0.8958 - val_loss: 0.4016 - val_accuracy: 0.8767\n",
      "Epoch 7/1000\n",
      "38/38 [==============================] - 46s 1s/step - loss: 0.3305 - accuracy: 0.8792 - val_loss: 0.4126 - val_accuracy: 0.8717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17c6ba990>"
      ]
     },
     "execution_count": 929,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "model.fit_generator(generator=train_generator2,epochs=1000,validation_data=(xValid , yValid), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1200 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_datagen=tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input, horizontal_flip=True, width_shift_range=0.22, zoom_range=0.1,\n",
    "    height_shift_range=0.22, shear_range=0.01, rotation_range=45, fill_mode=\"constant\", validation_split=0.00)\n",
    "train_generator3 = train_datagen.flow_from_directory('./train1200Classes/Classes', class_mode='categorical', target_size=(128,128), subset='training')\n",
    "#valid_generator = train_datagen.flow_from_directory('./train1200A/classes', class_mode='categorical', target_size=(128,128), subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.3497 - accuracy: 0.8717 - val_loss: 0.3706 - val_accuracy: 0.8833\n",
      "Epoch 2/1000\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.3969 - accuracy: 0.8567 - val_loss: 0.3763 - val_accuracy: 0.8833\n",
      "Epoch 3/1000\n",
      "38/38 [==============================] - 49s 1s/step - loss: 0.4130 - accuracy: 0.8575 - val_loss: 0.3750 - val_accuracy: 0.8850\n",
      "Epoch 4/1000\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.4105 - accuracy: 0.8517 - val_loss: 0.3763 - val_accuracy: 0.8817\n",
      "Epoch 5/1000\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.3744 - accuracy: 0.8558 - val_loss: 0.3713 - val_accuracy: 0.8850\n",
      "Epoch 6/1000\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.3884 - accuracy: 0.8658 - val_loss: 0.3635 - val_accuracy: 0.8850\n",
      "Epoch 7/1000\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.3691 - accuracy: 0.8692 - val_loss: 0.3637 - val_accuracy: 0.8817\n",
      "Epoch 8/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.3777 - accuracy: 0.8700 - val_loss: 0.3662 - val_accuracy: 0.8850\n",
      "Epoch 9/1000\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.3977 - accuracy: 0.8575 - val_loss: 0.3682 - val_accuracy: 0.8833\n",
      "Epoch 10/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.3689 - accuracy: 0.8675 - val_loss: 0.3777 - val_accuracy: 0.8833\n",
      "Epoch 11/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.3681 - accuracy: 0.8683 - val_loss: 0.3741 - val_accuracy: 0.8817\n",
      "Epoch 12/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.3810 - accuracy: 0.8717 - val_loss: 0.3746 - val_accuracy: 0.8817\n",
      "Epoch 13/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.3452 - accuracy: 0.8758 - val_loss: 0.3734 - val_accuracy: 0.8800\n",
      "Epoch 14/1000\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.3764 - accuracy: 0.8658 - val_loss: 0.3724 - val_accuracy: 0.8833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x187740750>"
      ]
     },
     "execution_count": 911,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "model.fit_generator(generator=train_generator3,epochs=1000,validation_data=(xValid , yValid), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following might be a bit risky, training only on validation data. (Maybe we should do it in anothe image data generator to avoiid overfiting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - 18s 943ms/step - loss: 0.1653 - accuracy: 0.9450\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 18s 948ms/step - loss: 0.1516 - accuracy: 0.9533\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 18s 949ms/step - loss: 0.1266 - accuracy: 0.9600\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 17s 907ms/step - loss: 0.1058 - accuracy: 0.9633\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 17s 918ms/step - loss: 0.1020 - accuracy: 0.9667\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 17s 920ms/step - loss: 0.1045 - accuracy: 0.9717\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 18s 931ms/step - loss: 0.0837 - accuracy: 0.9883\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 17s 915ms/step - loss: 0.0667 - accuracy: 0.9767\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 18s 973ms/step - loss: 0.0851 - accuracy: 0.9833\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 19s 974ms/step - loss: 0.0701 - accuracy: 0.9833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17d119a90>"
      ]
     },
     "execution_count": 754,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "model.fit(xValid , yValid,epochs=2, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model8/assets\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the saved model (If wanted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo1 = keras.models.load_model('saved_model/my_model4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the test set to fit the one passed with the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshapedTestPreprocessed = keras.applications.mobilenet.preprocess_input(testReshapedX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [],
   "source": [
    "p6 = model.predict(reshapedTestPreprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the uniformity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.5366074e-06, 1.0109969e-05, 9.9997783e-01, 1.7497619e-07,\n",
       "        4.3879591e-06, 4.0033797e-06],\n",
       "       [7.8312763e-07, 3.7874979e-06, 9.9999499e-01, 2.7511371e-09,\n",
       "        2.5645474e-07, 1.9849668e-07],\n",
       "       [8.1936613e-04, 3.5620792e-04, 1.2101792e-03, 3.1458385e-02,\n",
       "        9.6198946e-01, 4.1663754e-03],\n",
       "       ...,\n",
       "       [7.8578756e-07, 2.0418297e-04, 3.2544065e-06, 2.2660107e-08,\n",
       "        7.9142546e-06, 9.9978381e-01],\n",
       "       [1.7275155e-04, 3.8914832e-01, 1.2770750e-01, 7.5033848e-04,\n",
       "        4.6253806e-01, 1.9683031e-02],\n",
       "       [1.4065078e-02, 1.2698229e-03, 3.5135562e-03, 1.1184219e-02,\n",
       "        9.6800953e-01, 1.9577942e-03]], dtype=float32)"
      ]
     },
     "execution_count": 932,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9032.  9962. 10546. 10299. 10340.  9821.]\n"
     ]
    }
   ],
   "source": [
    "count = np.zeros(6)\n",
    "for i in p6:\n",
    "    count[np.argmax(i)] += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9796. 10292. 10241. 10205.  9648.  9818.]\n"
     ]
    }
   ],
   "source": [
    "count = np.zeros(6)\n",
    "for i in p5:\n",
    "    count[np.argmax(i)] += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9557.  9669. 10183.  9625. 10709. 10257.]\n"
     ]
    }
   ],
   "source": [
    "count = np.zeros(6)\n",
    "for i in p5:\n",
    "    count[np.argmax(i)] += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(p6,  axis=1)\n",
    "pred6 = pd.DataFrame(predictions)\n",
    "pred6.index.name = \"Id\"\n",
    "pred6 = pred6.rename(columns={0: \"Category\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Category\n",
       "Id          \n",
       "0          2\n",
       "1          2\n",
       "2          4\n",
       "3          0\n",
       "4          1\n",
       "5          2\n",
       "6          2\n",
       "7          4\n",
       "8          5\n",
       "9          5\n",
       "10         4\n",
       "11         1\n",
       "12         1\n",
       "13         1\n",
       "14         3\n",
       "15         3\n",
       "16         4\n",
       "17         3\n",
       "18         0\n",
       "19         3"
      ]
     },
     "execution_count": 936,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred6[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Category\n",
       "Id          \n",
       "0          2\n",
       "1          2\n",
       "2          4\n",
       "3          0\n",
       "4          2\n",
       "5          2\n",
       "6          2\n",
       "7          4\n",
       "8          5\n",
       "9          5\n",
       "10         1\n",
       "11         1\n",
       "12         1\n",
       "13         1\n",
       "14         4\n",
       "15         3\n",
       "16         2\n",
       "17         3\n",
       "18         0\n",
       "19         3"
      ]
     },
     "execution_count": 915,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred5[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Category\n",
       "Id          \n",
       "0          2\n",
       "1          2\n",
       "2          4\n",
       "3          0\n",
       "4          1\n",
       "5          2\n",
       "6          2\n",
       "7          4\n",
       "8          5\n",
       "9          5\n",
       "10         4\n",
       "11         1\n",
       "12         1\n",
       "13         1\n",
       "14         3\n",
       "15         3\n",
       "16         2\n",
       "17         3\n",
       "18         0\n",
       "19         3"
      ]
     },
     "execution_count": 839,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred5[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1842f1810>"
      ]
     },
     "execution_count": 937,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(testReshapedX[14]/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred6.to_csv('mobileNetTransferPredictions6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le reste est un bit gibberish mais je vais les garder juste pour que je me retrouve haha et me donner une baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8223. 10101. 10083.  8820. 11698. 11075.]\n"
     ]
    }
   ],
   "source": [
    "count = np.zeros(6)\n",
    "for i in p:\n",
    "    count[np.argmax(i)] += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9502.  9781. 10185. 10192. 10757.  9583.]\n"
     ]
    }
   ],
   "source": [
    "count = np.zeros(6)\n",
    "for i in p:\n",
    "    count[np.argmax(i)] += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9618.  8898.  9717.  9593. 11937. 10237.]\n"
     ]
    }
   ],
   "source": [
    "count = np.zeros(6)\n",
    "for i in p2:\n",
    "    count[np.argmax(i)] += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(p2,  axis=1)\n",
    "pred2 = pd.DataFrame(predictions)\n",
    "pred2.index.name = \"Id\"\n",
    "pred2 = pred2.rename(columns={0: \"Category\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Category\n",
       "Id          \n",
       "0          2\n",
       "1          2\n",
       "2          4\n",
       "3          0\n",
       "4          1\n",
       "5          2\n",
       "6          2\n",
       "7          4\n",
       "8          5\n",
       "9          5\n",
       "10         4\n",
       "11         1\n",
       "12         1\n",
       "13         1\n",
       "14         3\n",
       "15         3\n",
       "16         2\n",
       "17         3\n",
       "18         0\n",
       "19         3"
      ]
     },
     "execution_count": 846,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred5[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Category\n",
       "Id          \n",
       "0          2\n",
       "1          2\n",
       "2          4\n",
       "3          0\n",
       "4          4\n",
       "5          2\n",
       "6          2\n",
       "7          4\n",
       "8          5\n",
       "9          5\n",
       "10         0\n",
       "11         1\n",
       "12         1\n",
       "13         1\n",
       "14         5\n",
       "15         5\n",
       "16         4\n",
       "17         3\n",
       "18         0\n",
       "19         3"
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(p,  axis=1)\n",
    "pred = pd.DataFrame(predictions)\n",
    "pred.index.name = \"Id\"\n",
    "pred = pred.rename(columns={0: \"Category\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Category\n",
       "Id          \n",
       "0          2\n",
       "1          2\n",
       "2          4\n",
       "3          0\n",
       "4          2\n",
       "5          2\n",
       "6          2\n",
       "7          4\n",
       "8          3"
      ]
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Category\n",
       "Id          \n",
       "0          2\n",
       "1          2\n",
       "2          4\n",
       "3          0\n",
       "4          4\n",
       "5          2\n",
       "6          2\n",
       "7          4\n",
       "8          5\n",
       "9          0\n",
       "10         1\n",
       "11         1\n",
       "12         1\n",
       "13         1\n",
       "14         3\n",
       "15         3\n",
       "16         4\n",
       "17         3\n",
       "18         4\n",
       "19         3"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17d09e490>"
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(testReshapedX[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.to_csv('mobileNetTransferPredictions2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import gzip\n",
    "\n",
    "\n",
    "def one_hot(y, n_classes=6):\n",
    "    return np.eye(n_classes)[y]\n",
    "\n",
    "def load_mnist():\n",
    "    data_file = gzip.open(\"mnist.pkl.gz\", \"rb\")\n",
    "    train_data, val_data, test_data = pickle.load(data_file, encoding=\"latin1\")\n",
    "    data_file.close()\n",
    "\n",
    "    train_inputs = [np.reshape(x, (784, 1)) for x in train_data[0]]\n",
    "    train_results = [one_hot(y, 10) for y in train_data[1]]\n",
    "    train_data = np.array(train_inputs).reshape(-1, 784), np.array(train_results).reshape(-1, 10)\n",
    "\n",
    "    val_inputs = [np.reshape(x, (784, 1)) for x in val_data[0]]\n",
    "    val_results = [one_hot(y, 10) for y in val_data[1]]\n",
    "    val_data = np.array(val_inputs).reshape(-1, 784), np.array(val_results).reshape(-1, 10)\n",
    "\n",
    "    test_inputs = [np.reshape(x, (784, 1)) for x in test_data[0]]\n",
    "    test_data = list(zip(test_inputs, test_data[1]))\n",
    "\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainM, valM, testM = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainM_x, trainMy = trainM\n",
    "validM_x, validMy = valM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainM_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainM_y = np.argmax(trainMy, axis=1)\n",
    "validM_y = np.argmax(validMy,  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.where((trainM_y > 3))[0]\n",
    "resultV = np.where((validM_y > 3))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainMX = trainM_x[result] \n",
    "trainMY = one_hot(trainM_y[result]-4) \n",
    "\n",
    "validMX = validM_x[resultV] \n",
    "validMY = one_hot(validM_y[resultV]-4)\n",
    "\n",
    "trainMX = trainMX.reshape(-1, 28, 28, 1)\n",
    "validMX = validMX.reshape(-1, 28, 28, 1)\n",
    "\n",
    "\n",
    "trainMX = np.stack((trainMX.reshape(-1, 28,28),)*3, axis=-1)\n",
    "validMX = np.stack((validMX.reshape(-1, 28,28),)*3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29321, 28, 28, 3)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainMX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17602d8d0>"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAOJklEQVR4nO3dbawc5XnG8evC2AYMaW0olguGkGAgNKUmPQIaUAvipQSpMeQF4VSRK5E6IEhDFdRSqgo+UAm1EERRmuAEy6alkFQEYTW0xLgIlKpxOCADBgdMkB3sGpsXgU0p9vHh7oczjg5w5tnj3dkXc/9/0tHuzr2zc2vlyzM7z84+jggB+PDbr98NAOgNwg4kQdiBJAg7kARhB5LYv5cbm+bpcYBm9HKTQCrv6H+1K3Z6olpHYbd9vqRbJU2R9L2IuLH0/AM0Q6f67E42CaBgdayqrbV9GG97iqRvSfqMpBMlLbR9YruvB6C7OvnMfoqkFyLixYjYJekeSQuaaQtA0zoJ+xGSXhr3eFO17D1sL7Y9bHt4RDs72ByATnT9bHxELImIoYgYmqrp3d4cgBqdhH2zpLnjHh9ZLQMwgDoJ+2OS5tk+xvY0SZdIWtFMWwCa1vbQW0Tstn2lpAc1NvS2NCKeaawzAI3qaJw9Ih6Q9EBDvQDoIr4uCyRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiioymbbW+QtEPSqKTdETHURFMAmtdR2CtnRcSrDbwOgC7iMB5IotOwh6Qf237c9uKJnmB7se1h28Mj2tnh5gC0q9PD+DMiYrPtwyWttP3ziHh0/BMiYomkJZL0Ec+KDrcHoE0d7dkjYnN1u03SfZJOaaIpAM1rO+y2Z9g+ZM99SedJWttUYwCa1clh/GxJ99ne8zr/EhH/0UhXABrXdtgj4kVJv9NgLwC6iKE3IAnCDiRB2IEkCDuQBGEHkmjiQhgMsF1/WL4QceMfv1usX/6pR4r1q2Y+v9c97fHb3/tasX7QlvIXLt/4dPnr10ffVb8vm/bgcHHdDyP27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOPsHwKvXPZ7tbXb/uJbxXWHpo8W6/u12B8s2nBOsX7yr/2ytvbkV24trttKq94+PWthbW3Wgx1tep/Enh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcfQB46rRi/Z1zyj/ie+9f/X1t7Tf3n15c99KN5xbrG286vlif8aM1xfrDBx1VW3vkvuOK6947b0Wx3sr2NYfW1mZ19Mr7JvbsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+wDYMuV5d92/9nVra77rh9L/+ILf1Rcc/fnR4r1g15dXayXf9ld+p/Fv1tbWz2vs+vZ//3tQ4r1Y29/qba2u6Mt75ta7tltL7W9zfbacctm2V5pe311O7O7bQLo1GQO45dJOv99y66RtCoi5klaVT0GMMBahj0iHpX0+vsWL5C0vLq/XNKFDfcFoGHtfmafHRFbqvsvS5pd90TbiyUtlqQDdFCbmwPQqY7PxkdEqHCeJiKWRMRQRAxNLZxIAtBd7YZ9q+05klTdbmuuJQDd0G7YV0haVN1fJOn+ZtoB0C0tP7PbvlvSmZIOs71J0nWSbpT0A9uXStoo6eJuNrmvW3/bqcX6c5+7rVgvz6AufWLlZbW1E67eUFx39NXXWrx6Zy67vHv7gRv+dlGxPvOl/+7atvdFLcMeEXW/tH92w70A6CK+LgskQdiBJAg7kARhB5Ig7EASXOLagF/cfFqx/tznytMmv/nuO8X6F3/+pWL9+K89X1sb3bGjuG4r+82YUay/9oWTivUFB9f/zPV+OrC47gn/ekWxfuwyhtb2Bnt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfZJmjL78Nra8ov+sbjuuy0uUm01jj7t3I0tXr99+80/sVj/5NJ1xfoNs/+hxRbqf53o9DWXFNc8/vrytkdbbBnvxZ4dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnH2SfED9ePHQ9M5GfA/8s2nlbR89t1hff9mRtbXzznmiuO6fH76kWD9q//I1563G+EejflJnf/+w8rpvrG/x6tgb7NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2Scp3tlZW1u9c2px3VOnjxTr9z90T7He6nr4Tjz0f+Wx7vUj9ePkknTWgW8V68O76r9D8Ot38rvvvdRyz257qe1ttteOW3a97c2211R/F3S3TQCdmsxh/DJJ50+w/JaImF/9PdBsWwCa1jLsEfGopNd70AuALurkBN2Vtp+qDvNn1j3J9mLbw7aHR1T/uRdAd7Ub9m9L+rik+ZK2SLq57okRsSQihiJiaGrhxwcBdFdbYY+IrRExGhHvSvqupFOabQtA09oKu+054x5eJGlt3XMBDIaW4+y275Z0pqTDbG+SdJ2kM23PlxSSNkj6ahd7HAijW7fV1q67/CvFdW/6Tvl35U8qX86uf95evp79hkc+W1s7bll57vf9t75ZrB9+d/nc7Flz/7NYX/Rw/XtznIaL66JZLcMeEQsnWHxHF3oB0EV8XRZIgrADSRB2IAnCDiRB2IEkuMS1AdMeLA8hXXtMd79zdJx+1va6OxaUe/vRUfcX6yNR3l8cuKHFuCJ6hj07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOHtyuw8s/38/EuXpqFv9zPUxy35Zv+3immgae3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9uQOueen5SfUzvWDfQ17diAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH25HZcclqLZzzekz7QfS337Lbn2n7Y9rO2n7H99Wr5LNsrba+vbmd2v10A7ZrMYfxuSd+IiBMlnSbpCtsnSrpG0qqImCdpVfUYwIBqGfaI2BIRT1T3d0haJ+kISQskLa+etlzShd1qEkDn9uozu+2PSjpZ0mpJsyNiS1V6WdLsmnUWS1osSQfooHb7BNChSZ+Nt32wpHslXRUR28fXIiIkxUTrRcSSiBiKiKGpmt5RswDaN6mw256qsaDfFRE/rBZvtT2nqs+RtK07LQJoQsvDeNuWdIekdRHxzXGlFZIWSbqxui3P7YuB9ObH+KpFFpP5zH66pC9Letr2mmrZtRoL+Q9sXyppo6SLu9MigCa0DHtE/ESSa8pnN9sOgG7hGA5IgrADSRB2IAnCDiRB2IEkuMQ1uSMeebtYn3rllGJ9ZMLvTWIQsWcHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZ0/O/7WmWF+2/fBifeEhm4v1t39rTm1t2kubiuuiWezZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtlRdMvtXyjWF159a7E+529eqK299sZJ5Y3/9KlyHXuFPTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJOGI8g9/254r6U5JsyWFpCURcavt6yX9qaRXqqdeGxEPlF7rI54Vp5qJX/clUw47tFifdm/5qxrfP/bfamt/8OTC4rqzvvRKsT76xpvFekarY5W2x+sTzro8mS/V7Jb0jYh4wvYhkh63vbKq3RIRNzXVKIDumcz87Fskbanu77C9TtIR3W4MQLP26jO77Y9KOlnS6mrRlbafsr3U9syadRbbHrY9PKKdHTULoH2TDrvtgyXdK+mqiNgu6duSPi5pvsb2/DdPtF5ELImIoYgYmqrpDbQMoB2TCrvtqRoL+l0R8UNJioitETEaEe9K+q6kU7rXJoBOtQy7bUu6Q9K6iPjmuOXjfzb0Iklrm28PQFMmczb+dElflvS07T2/O3ytpIW252tsOG6DpK92pUP01eirrxXruz5fHpr7xM31/yzWnXN7cd3PnnBpsc4lsHtnMmfjfyJponG74pg6gMHCN+iAJAg7kARhB5Ig7EAShB1IgrADSbS8xLVJXOIKdFfpElf27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQRE/H2W2/ImnjuEWHSXq1Zw3snUHtbVD7kuitXU32dnRE/MZEhZ6G/QMbt4cjYqhvDRQMam+D2pdEb+3qVW8cxgNJEHYgiX6HfUmft18yqL0Nal8SvbWrJ7319TM7gN7p954dQI8QdiCJvoTd9vm2n7P9gu1r+tFDHdsbbD9te43t4T73stT2Nttrxy2bZXul7fXV7YRz7PWpt+ttb67euzW2L+hTb3NtP2z7WdvP2P56tbyv712hr568bz3/zG57iqTnJZ0raZOkxyQtjIhne9pIDdsbJA1FRN+/gGH79yW9JenOiPhktezvJL0eETdW/1HOjIi/HJDerpf0Vr+n8a5mK5ozfppxSRdK+hP18b0r9HWxevC+9WPPfoqkFyLixYjYJekeSQv60MfAi4hHJb3+vsULJC2v7i/X2D+WnqvpbSBExJaIeKK6v0PSnmnG+/reFfrqiX6E/QhJL417vEmDNd97SPqx7cdtL+53MxOYHRFbqvsvS5rdz2Ym0HIa71563zTjA/PetTP9eac4QfdBZ0TEpyR9RtIV1eHqQIqxz2CDNHY6qWm8e2WCacZ/pZ/vXbvTn3eqH2HfLGnuuMdHVssGQkRsrm63SbpPgzcV9dY9M+hWt9v63M+vDNI03hNNM64BeO/6Of15P8L+mKR5to+xPU3SJZJW9KGPD7A9ozpxItszJJ2nwZuKeoWkRdX9RZLu72Mv7zEo03jXTTOuPr93fZ/+PCJ6/ifpAo2dkf+FpL/uRw81fX1M0pPV3zP97k3S3Ro7rBvR2LmNSyUdKmmVpPWSHpI0a4B6+ydJT0t6SmPBmtOn3s7Q2CH6U5LWVH8X9Pu9K/TVk/eNr8sCSXCCDkiCsANJEHYgCcIOJEHYgSQIO5AEYQeS+H+ctitrvLo9awAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(trainMX[2].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1760f6190>"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(trainMX[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the CNN model\n",
    "def cnn_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(28, 28, 3), strides=(1, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', strides=(1, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', strides=(1, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 68,966\n",
      "Trainable params: 68,966\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m = cnn_model()\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "917/917 [==============================] - 16s 18ms/step - loss: 0.2280 - accuracy: 0.9203 - val_loss: 0.0742 - val_accuracy: 0.9796\n",
      "Epoch 2/6\n",
      "917/917 [==============================] - 16s 18ms/step - loss: 0.0636 - accuracy: 0.9800 - val_loss: 0.0459 - val_accuracy: 0.9863\n",
      "Epoch 3/6\n",
      "917/917 [==============================] - 17s 19ms/step - loss: 0.0446 - accuracy: 0.9859 - val_loss: 0.0512 - val_accuracy: 0.9855\n",
      "Epoch 4/6\n",
      "917/917 [==============================] - 13s 15ms/step - loss: 0.0352 - accuracy: 0.9885 - val_loss: 0.0411 - val_accuracy: 0.9884\n",
      "Epoch 5/6\n",
      "917/917 [==============================] - 14s 15ms/step - loss: 0.0277 - accuracy: 0.9912 - val_loss: 0.0586 - val_accuracy: 0.9840\n",
      "Epoch 6/6\n",
      "917/917 [==============================] - 14s 16ms/step - loss: 0.0220 - accuracy: 0.9925 - val_loss: 0.0700 - val_accuracy: 0.9831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x178cc7650>"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(trainMX, trainMY,\n",
    "          epochs=6,\n",
    "          batch_size=32,\n",
    "          validation_data=(validMX, validMY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (idx, l) in enumerate(m.layers):  \n",
    "    l.trainable = False\n",
    "    if idx > 4:\n",
    "        l.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 68,966\n",
      "Trainable params: 12,646\n",
      "Non-trainable params: 56,320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1200 images belonging to 6 classes.\n",
      "Found 0 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_datagen=tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    horizontal_flip=True, width_shift_range=0.1, zoom_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.01, rotation_range=15, fill_mode=\"constant\", rescale=1./255, validation_split=0.00)\n",
    "train_gen = train_datagen.flow_from_directory('./train1200A/classes', class_mode='categorical', target_size=(28,28), subset='training')\n",
    "valid_gen = train_datagen.flow_from_directory('./train1200A/classes', class_mode='categorical', target_size=(28,28), subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 28, 28, 3)\n",
      "(32, 6)\n"
     ]
    }
   ],
   "source": [
    "x, y = train_generator[0]\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99609375"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainMX[21].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99762714"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[21].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1788f4390>"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[20])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 28, 28, 3)"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xValid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 6)"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yValid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "#         rotation_range=15,\n",
    "#         width_shift_range=0.15,\n",
    "#         height_shift_range=0.15,\n",
    "#         shear_range=0.00,\n",
    "#         zoom_range=0.1,\n",
    "#         rescale=1./255,\n",
    "#         horizontal_flip=True,\n",
    "#         fill_mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it = datagen.flow(xTrain, yT, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 28, 28, 3)"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x, y = it[0]\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 2s 46ms/step - loss: 2.0956 - accuracy: 0.2217 - val_loss: 1.7477 - val_accuracy: 0.2567\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.6888 - accuracy: 0.2808 - val_loss: 1.6232 - val_accuracy: 0.3317\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.6038 - accuracy: 0.3225 - val_loss: 1.5808 - val_accuracy: 0.3700\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.5128 - accuracy: 0.3542 - val_loss: 1.4620 - val_accuracy: 0.3733\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.4694 - accuracy: 0.3858 - val_loss: 1.4510 - val_accuracy: 0.4317\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.4153 - accuracy: 0.4192 - val_loss: 1.3898 - val_accuracy: 0.4450\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.4094 - accuracy: 0.4258 - val_loss: 1.3894 - val_accuracy: 0.4450\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.3902 - accuracy: 0.4392 - val_loss: 1.3412 - val_accuracy: 0.4633\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.3133 - accuracy: 0.4700 - val_loss: 1.4408 - val_accuracy: 0.4417\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.2503 - accuracy: 0.4883 - val_loss: 1.2829 - val_accuracy: 0.5150\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 1.2837 - accuracy: 0.5033 - val_loss: 1.1886 - val_accuracy: 0.5550\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 1.1657 - accuracy: 0.5467 - val_loss: 1.1650 - val_accuracy: 0.5700\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.1503 - accuracy: 0.5492 - val_loss: 1.0958 - val_accuracy: 0.5983\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.0938 - accuracy: 0.5792 - val_loss: 1.1513 - val_accuracy: 0.5900\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 1.1506 - accuracy: 0.5675 - val_loss: 1.0369 - val_accuracy: 0.6017\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.0910 - accuracy: 0.5917 - val_loss: 1.0371 - val_accuracy: 0.6367\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.0336 - accuracy: 0.6083 - val_loss: 1.0130 - val_accuracy: 0.6400\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.0331 - accuracy: 0.6183 - val_loss: 0.9985 - val_accuracy: 0.6300\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 1.0198 - accuracy: 0.6117 - val_loss: 0.9613 - val_accuracy: 0.6300\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9710 - accuracy: 0.6350 - val_loss: 0.9686 - val_accuracy: 0.6333\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.9397 - accuracy: 0.6567 - val_loss: 0.9799 - val_accuracy: 0.6233\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.9663 - accuracy: 0.6467 - val_loss: 0.9581 - val_accuracy: 0.6467\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9453 - accuracy: 0.6500 - val_loss: 0.9853 - val_accuracy: 0.6717\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.9102 - accuracy: 0.6800 - val_loss: 0.9873 - val_accuracy: 0.6517\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 2s 47ms/step - loss: 0.9089 - accuracy: 0.6683 - val_loss: 1.0552 - val_accuracy: 0.6417\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.9014 - accuracy: 0.6917 - val_loss: 0.9226 - val_accuracy: 0.6650\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.9160 - accuracy: 0.6583 - val_loss: 0.8926 - val_accuracy: 0.6800\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8558 - accuracy: 0.6825 - val_loss: 0.9207 - val_accuracy: 0.6833\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8295 - accuracy: 0.6867 - val_loss: 0.9112 - val_accuracy: 0.6817\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8591 - accuracy: 0.6800 - val_loss: 1.0058 - val_accuracy: 0.6583\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.8215 - accuracy: 0.7017 - val_loss: 0.9982 - val_accuracy: 0.6683\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.8207 - accuracy: 0.7117 - val_loss: 0.9087 - val_accuracy: 0.6783\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.8129 - accuracy: 0.7158 - val_loss: 0.9412 - val_accuracy: 0.6733\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.7686 - accuracy: 0.7308 - val_loss: 0.8995 - val_accuracy: 0.6967\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.8196 - accuracy: 0.6992 - val_loss: 0.9049 - val_accuracy: 0.6883\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7735 - accuracy: 0.7192 - val_loss: 0.9526 - val_accuracy: 0.6967\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7191 - accuracy: 0.7292 - val_loss: 0.8973 - val_accuracy: 0.6950\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7411 - accuracy: 0.7308 - val_loss: 0.9241 - val_accuracy: 0.6917\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7389 - accuracy: 0.7358 - val_loss: 0.9935 - val_accuracy: 0.7083\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.7301 - accuracy: 0.7350 - val_loss: 0.9169 - val_accuracy: 0.7100\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7249 - accuracy: 0.7317 - val_loss: 0.9665 - val_accuracy: 0.6867\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7359 - accuracy: 0.7400 - val_loss: 0.8864 - val_accuracy: 0.7033\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.7625 - accuracy: 0.7275 - val_loss: 0.9033 - val_accuracy: 0.6950\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.7258 - accuracy: 0.7508 - val_loss: 0.9601 - val_accuracy: 0.6833\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.7083 - accuracy: 0.7475 - val_loss: 0.8687 - val_accuracy: 0.7183\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.7422 - accuracy: 0.7233 - val_loss: 0.8412 - val_accuracy: 0.7083\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.7542 - accuracy: 0.7275 - val_loss: 0.9100 - val_accuracy: 0.6867\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.7129 - accuracy: 0.7450 - val_loss: 0.9162 - val_accuracy: 0.6983\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.6941 - accuracy: 0.7450 - val_loss: 0.9658 - val_accuracy: 0.6800\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.6800 - accuracy: 0.7475 - val_loss: 0.8520 - val_accuracy: 0.7100\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.6648 - accuracy: 0.7567 - val_loss: 0.9262 - val_accuracy: 0.7067\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.7199 - accuracy: 0.7375 - val_loss: 0.8770 - val_accuracy: 0.7100\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 2s 44ms/step - loss: 0.6792 - accuracy: 0.7575 - val_loss: 0.9740 - val_accuracy: 0.6700\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 2s 43ms/step - loss: 0.6965 - accuracy: 0.7467 - val_loss: 0.9077 - val_accuracy: 0.7150\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.6616 - accuracy: 0.7617 - val_loss: 0.8490 - val_accuracy: 0.7250\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.6676 - accuracy: 0.7592 - val_loss: 0.8477 - val_accuracy: 0.7133\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.6651 - accuracy: 0.7633 - val_loss: 0.8333 - val_accuracy: 0.7167\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.6473 - accuracy: 0.7800 - val_loss: 0.8471 - val_accuracy: 0.7250\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.6526 - accuracy: 0.7550 - val_loss: 0.8707 - val_accuracy: 0.7167\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.6684 - accuracy: 0.7550 - val_loss: 0.8633 - val_accuracy: 0.7183\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.6385 - accuracy: 0.7658 - val_loss: 0.9033 - val_accuracy: 0.7000\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.6013 - accuracy: 0.7825 - val_loss: 0.8764 - val_accuracy: 0.7233\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.6182 - accuracy: 0.7617 - val_loss: 0.8167 - val_accuracy: 0.7233\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.6338 - accuracy: 0.7742 - val_loss: 0.8736 - val_accuracy: 0.7067\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.5955 - accuracy: 0.7950 - val_loss: 0.9170 - val_accuracy: 0.6983\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.6276 - accuracy: 0.7742 - val_loss: 1.0310 - val_accuracy: 0.6967\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.6383 - accuracy: 0.7692 - val_loss: 0.8996 - val_accuracy: 0.7067\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5954 - accuracy: 0.7867 - val_loss: 0.8752 - val_accuracy: 0.7183\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 2s 43ms/step - loss: 0.6257 - accuracy: 0.7725 - val_loss: 0.8776 - val_accuracy: 0.7283\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5753 - accuracy: 0.7925 - val_loss: 0.9160 - val_accuracy: 0.7200\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.6226 - accuracy: 0.7725 - val_loss: 0.8892 - val_accuracy: 0.7267\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.5935 - accuracy: 0.7875 - val_loss: 0.8757 - val_accuracy: 0.7250\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.5968 - accuracy: 0.7983 - val_loss: 0.8674 - val_accuracy: 0.7367\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.6207 - accuracy: 0.7883 - val_loss: 0.9311 - val_accuracy: 0.7000\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.6148 - accuracy: 0.7783 - val_loss: 0.8697 - val_accuracy: 0.7100\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.5630 - accuracy: 0.7983 - val_loss: 0.8576 - val_accuracy: 0.7383\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.5516 - accuracy: 0.7925 - val_loss: 0.8758 - val_accuracy: 0.7233\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5517 - accuracy: 0.8042 - val_loss: 0.8700 - val_accuracy: 0.7133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x178ec4050>"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "m.fit_generator(generator=train_generator,epochs=100, validation_data=(xValid /255, yValid), callbacks=[callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5486 - accuracy: 0.8092 - val_loss: 0.7434 - val_accuracy: 0.7967\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.5189 - accuracy: 0.8058 - val_loss: 0.7437 - val_accuracy: 0.7967\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.4819 - accuracy: 0.8192 - val_loss: 0.7436 - val_accuracy: 0.7967\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5141 - accuracy: 0.8125 - val_loss: 0.7441 - val_accuracy: 0.7967\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.4834 - accuracy: 0.8267 - val_loss: 0.7445 - val_accuracy: 0.7967\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5031 - accuracy: 0.8258 - val_loss: 0.7449 - val_accuracy: 0.7983\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.5409 - accuracy: 0.8100 - val_loss: 0.7448 - val_accuracy: 0.7950\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 2s 44ms/step - loss: 0.4928 - accuracy: 0.8325 - val_loss: 0.7449 - val_accuracy: 0.7950\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5268 - accuracy: 0.8158 - val_loss: 0.7447 - val_accuracy: 0.7950\n",
      "Epoch 10/100\n",
      " 3/38 [=>............................] - ETA: 0s - loss: 0.4635 - accuracy: 0.8438"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-563-5b23079930fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxValid\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myValid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "m.fit_generator(generator=train_generator,epochs=100, validation_data=(xValid /255, yValid), callbacks=[callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 3s 83ms/step - loss: 0.5813 - accuracy: 0.7992 - val_loss: 0.7052 - val_accuracy: 0.7817\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 3s 66ms/step - loss: 0.5238 - accuracy: 0.8050 - val_loss: 0.9033 - val_accuracy: 0.7617\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 3s 75ms/step - loss: 0.5812 - accuracy: 0.8033 - val_loss: 0.8731 - val_accuracy: 0.7633\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 3s 72ms/step - loss: 0.5326 - accuracy: 0.8058 - val_loss: 0.7914 - val_accuracy: 0.7850\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 3s 73ms/step - loss: 0.5536 - accuracy: 0.8000 - val_loss: 0.7891 - val_accuracy: 0.7683\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 3s 74ms/step - loss: 0.5305 - accuracy: 0.8150 - val_loss: 0.7104 - val_accuracy: 0.7800\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 3s 74ms/step - loss: 0.5152 - accuracy: 0.8133 - val_loss: 0.7752 - val_accuracy: 0.7867\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 3s 72ms/step - loss: 0.5197 - accuracy: 0.8183 - val_loss: 0.7379 - val_accuracy: 0.7950\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 3s 71ms/step - loss: 0.5646 - accuracy: 0.8092 - val_loss: 0.8160 - val_accuracy: 0.7733\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 3s 73ms/step - loss: 0.5536 - accuracy: 0.8008 - val_loss: 0.7101 - val_accuracy: 0.7917\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 3s 67ms/step - loss: 0.5521 - accuracy: 0.8008 - val_loss: 0.8061 - val_accuracy: 0.7733\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 3s 74ms/step - loss: 0.5121 - accuracy: 0.8125 - val_loss: 0.8224 - val_accuracy: 0.7650\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 3s 74ms/step - loss: 0.5468 - accuracy: 0.8033 - val_loss: 0.7180 - val_accuracy: 0.7883\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 3s 73ms/step - loss: 0.5272 - accuracy: 0.8125 - val_loss: 0.7159 - val_accuracy: 0.7817\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 3s 78ms/step - loss: 0.5277 - accuracy: 0.8133 - val_loss: 0.7321 - val_accuracy: 0.7883\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 3s 72ms/step - loss: 0.5288 - accuracy: 0.8017 - val_loss: 0.6794 - val_accuracy: 0.8017\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 3s 76ms/step - loss: 0.5470 - accuracy: 0.8100 - val_loss: 0.8035 - val_accuracy: 0.7750\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 3s 72ms/step - loss: 0.5092 - accuracy: 0.8167 - val_loss: 0.7163 - val_accuracy: 0.7883\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 3s 77ms/step - loss: 0.5045 - accuracy: 0.8267 - val_loss: 0.8245 - val_accuracy: 0.7700\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 3s 76ms/step - loss: 0.5051 - accuracy: 0.8175 - val_loss: 0.7745 - val_accuracy: 0.7950\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 3s 76ms/step - loss: 0.5337 - accuracy: 0.8150 - val_loss: 0.8527 - val_accuracy: 0.7750\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 3s 80ms/step - loss: 0.4676 - accuracy: 0.8300 - val_loss: 0.8004 - val_accuracy: 0.7783\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 3s 75ms/step - loss: 0.4889 - accuracy: 0.8167 - val_loss: 0.7726 - val_accuracy: 0.7900\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 3s 75ms/step - loss: 0.4596 - accuracy: 0.8333 - val_loss: 0.7963 - val_accuracy: 0.7783\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 3s 75ms/step - loss: 0.5004 - accuracy: 0.8267 - val_loss: 0.8433 - val_accuracy: 0.7767\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 3s 75ms/step - loss: 0.5009 - accuracy: 0.8225 - val_loss: 0.8645 - val_accuracy: 0.7667\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 3s 72ms/step - loss: 0.5193 - accuracy: 0.8175 - val_loss: 0.7546 - val_accuracy: 0.7767\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 3s 75ms/step - loss: 0.4956 - accuracy: 0.8183 - val_loss: 0.7458 - val_accuracy: 0.7850\n",
      "Epoch 29/100\n",
      "24/38 [=================>............] - ETA: 0s - loss: 0.5080 - accuracy: 0.8190"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-565-5b23079930fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxValid\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myValid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "m.fit_generator(generator=train_generator,epochs=100, validation_data=(xValid /255, yValid), callbacks=[callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.compile(optimizer=keras.optimizers.Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5116 - accuracy: 0.8092 - val_loss: 0.7589 - val_accuracy: 0.7900\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.5315 - accuracy: 0.8108 - val_loss: 0.7586 - val_accuracy: 0.7917\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5319 - accuracy: 0.7992 - val_loss: 0.7581 - val_accuracy: 0.7900\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.5352 - accuracy: 0.8108 - val_loss: 0.7575 - val_accuracy: 0.7883\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.5630 - accuracy: 0.8117 - val_loss: 0.7569 - val_accuracy: 0.7900\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.5275 - accuracy: 0.8058 - val_loss: 0.7563 - val_accuracy: 0.7900\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.5299 - accuracy: 0.8117 - val_loss: 0.7555 - val_accuracy: 0.7900\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.5423 - accuracy: 0.8083 - val_loss: 0.7548 - val_accuracy: 0.7900\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5352 - accuracy: 0.8067 - val_loss: 0.7549 - val_accuracy: 0.7900\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5113 - accuracy: 0.8233 - val_loss: 0.7551 - val_accuracy: 0.7917\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.5184 - accuracy: 0.8242 - val_loss: 0.7545 - val_accuracy: 0.7917\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.5312 - accuracy: 0.8050 - val_loss: 0.7547 - val_accuracy: 0.7917\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5602 - accuracy: 0.7950 - val_loss: 0.7541 - val_accuracy: 0.7917\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.5235 - accuracy: 0.7983 - val_loss: 0.7535 - val_accuracy: 0.7917\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.5319 - accuracy: 0.8175 - val_loss: 0.7533 - val_accuracy: 0.7883\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5150 - accuracy: 0.8083 - val_loss: 0.7530 - val_accuracy: 0.7900\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 2s 39ms/step - loss: 0.5200 - accuracy: 0.8075 - val_loss: 0.7529 - val_accuracy: 0.7917\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.5220 - accuracy: 0.8017 - val_loss: 0.7531 - val_accuracy: 0.7950\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5043 - accuracy: 0.8125 - val_loss: 0.7529 - val_accuracy: 0.7933\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.5328 - accuracy: 0.8183 - val_loss: 0.7528 - val_accuracy: 0.7933\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.4801 - accuracy: 0.8250 - val_loss: 0.7532 - val_accuracy: 0.7933\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5211 - accuracy: 0.8125 - val_loss: 0.7526 - val_accuracy: 0.7933\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5219 - accuracy: 0.8058 - val_loss: 0.7522 - val_accuracy: 0.7933\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.5243 - accuracy: 0.8083 - val_loss: 0.7517 - val_accuracy: 0.7917\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5530 - accuracy: 0.8117 - val_loss: 0.7518 - val_accuracy: 0.7917\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.5307 - accuracy: 0.8050 - val_loss: 0.7514 - val_accuracy: 0.7950\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.4936 - accuracy: 0.8325 - val_loss: 0.7515 - val_accuracy: 0.7950\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.5168 - accuracy: 0.8108 - val_loss: 0.7515 - val_accuracy: 0.7950\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5226 - accuracy: 0.8033 - val_loss: 0.7515 - val_accuracy: 0.7933\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5314 - accuracy: 0.8025 - val_loss: 0.7513 - val_accuracy: 0.7933\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.5192 - accuracy: 0.8225 - val_loss: 0.7516 - val_accuracy: 0.7933\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5272 - accuracy: 0.8133 - val_loss: 0.7519 - val_accuracy: 0.7933\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5475 - accuracy: 0.8075 - val_loss: 0.7519 - val_accuracy: 0.7933\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 2s 39ms/step - loss: 0.5263 - accuracy: 0.8158 - val_loss: 0.7518 - val_accuracy: 0.7950\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.5241 - accuracy: 0.8225 - val_loss: 0.7513 - val_accuracy: 0.7933\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 2s 43ms/step - loss: 0.5574 - accuracy: 0.8033 - val_loss: 0.7509 - val_accuracy: 0.7950\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5105 - accuracy: 0.8233 - val_loss: 0.7507 - val_accuracy: 0.7950\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5413 - accuracy: 0.8058 - val_loss: 0.7505 - val_accuracy: 0.7950\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.4994 - accuracy: 0.8125 - val_loss: 0.7503 - val_accuracy: 0.7950\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.5442 - accuracy: 0.8125 - val_loss: 0.7504 - val_accuracy: 0.7950\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.5257 - accuracy: 0.8200 - val_loss: 0.7506 - val_accuracy: 0.7950\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5170 - accuracy: 0.8142 - val_loss: 0.7506 - val_accuracy: 0.7950\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.4894 - accuracy: 0.8217 - val_loss: 0.7513 - val_accuracy: 0.7950\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5757 - accuracy: 0.7942 - val_loss: 0.7510 - val_accuracy: 0.7967\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5052 - accuracy: 0.8192 - val_loss: 0.7508 - val_accuracy: 0.7967\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.4906 - accuracy: 0.8375 - val_loss: 0.7509 - val_accuracy: 0.7967\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5382 - accuracy: 0.8175 - val_loss: 0.7505 - val_accuracy: 0.7967\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5231 - accuracy: 0.7975 - val_loss: 0.7505 - val_accuracy: 0.7950\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5440 - accuracy: 0.7992 - val_loss: 0.7501 - val_accuracy: 0.7950\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5294 - accuracy: 0.8125 - val_loss: 0.7496 - val_accuracy: 0.7967\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5234 - accuracy: 0.8017 - val_loss: 0.7493 - val_accuracy: 0.7967\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.5131 - accuracy: 0.8183 - val_loss: 0.7491 - val_accuracy: 0.7967\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.5256 - accuracy: 0.7942 - val_loss: 0.7495 - val_accuracy: 0.7967\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5362 - accuracy: 0.8033 - val_loss: 0.7495 - val_accuracy: 0.7967\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5173 - accuracy: 0.8117 - val_loss: 0.7501 - val_accuracy: 0.7967\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.5168 - accuracy: 0.8083 - val_loss: 0.7500 - val_accuracy: 0.7950\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.5024 - accuracy: 0.8150 - val_loss: 0.7501 - val_accuracy: 0.7950\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5402 - accuracy: 0.7958 - val_loss: 0.7493 - val_accuracy: 0.7983\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.4972 - accuracy: 0.8225 - val_loss: 0.7490 - val_accuracy: 0.7983\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.5226 - accuracy: 0.8167 - val_loss: 0.7493 - val_accuracy: 0.7983\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5110 - accuracy: 0.8183 - val_loss: 0.7490 - val_accuracy: 0.7983\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5269 - accuracy: 0.8208 - val_loss: 0.7485 - val_accuracy: 0.7983\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5186 - accuracy: 0.8225 - val_loss: 0.7486 - val_accuracy: 0.7983\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5491 - accuracy: 0.8025 - val_loss: 0.7488 - val_accuracy: 0.7983\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.5303 - accuracy: 0.8033 - val_loss: 0.7486 - val_accuracy: 0.7983\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5330 - accuracy: 0.8117 - val_loss: 0.7490 - val_accuracy: 0.7983\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5223 - accuracy: 0.8033 - val_loss: 0.7491 - val_accuracy: 0.7983\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5458 - accuracy: 0.8100 - val_loss: 0.7491 - val_accuracy: 0.7967\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5578 - accuracy: 0.7908 - val_loss: 0.7487 - val_accuracy: 0.7967\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.5235 - accuracy: 0.8092 - val_loss: 0.7486 - val_accuracy: 0.7967\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5312 - accuracy: 0.8175 - val_loss: 0.7486 - val_accuracy: 0.7983\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5341 - accuracy: 0.8142 - val_loss: 0.7484 - val_accuracy: 0.7983\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.4895 - accuracy: 0.8158 - val_loss: 0.7487 - val_accuracy: 0.7983\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5268 - accuracy: 0.8000 - val_loss: 0.7490 - val_accuracy: 0.7983\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5196 - accuracy: 0.8225 - val_loss: 0.7489 - val_accuracy: 0.7983\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5147 - accuracy: 0.8150 - val_loss: 0.7486 - val_accuracy: 0.8000\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.5095 - accuracy: 0.8183 - val_loss: 0.7486 - val_accuracy: 0.8000\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5358 - accuracy: 0.8125 - val_loss: 0.7487 - val_accuracy: 0.8000\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5150 - accuracy: 0.8150 - val_loss: 0.7488 - val_accuracy: 0.8000\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5161 - accuracy: 0.8125 - val_loss: 0.7486 - val_accuracy: 0.8000\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5251 - accuracy: 0.8125 - val_loss: 0.7487 - val_accuracy: 0.8000\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5259 - accuracy: 0.8083 - val_loss: 0.7486 - val_accuracy: 0.8000\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.5259 - accuracy: 0.8092 - val_loss: 0.7484 - val_accuracy: 0.8000\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5397 - accuracy: 0.8008 - val_loss: 0.7480 - val_accuracy: 0.8000\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5344 - accuracy: 0.8167 - val_loss: 0.7478 - val_accuracy: 0.8000\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5049 - accuracy: 0.8142 - val_loss: 0.7478 - val_accuracy: 0.8000\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5534 - accuracy: 0.8042 - val_loss: 0.7471 - val_accuracy: 0.8000\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 2s 43ms/step - loss: 0.5255 - accuracy: 0.8133 - val_loss: 0.7470 - val_accuracy: 0.8000\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5281 - accuracy: 0.8000 - val_loss: 0.7471 - val_accuracy: 0.8000\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5261 - accuracy: 0.8133 - val_loss: 0.7475 - val_accuracy: 0.8000\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 2s 46ms/step - loss: 0.5394 - accuracy: 0.8083 - val_loss: 0.7474 - val_accuracy: 0.8000\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 2s 44ms/step - loss: 0.5117 - accuracy: 0.8225 - val_loss: 0.7470 - val_accuracy: 0.8000\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 2s 44ms/step - loss: 0.5136 - accuracy: 0.8267 - val_loss: 0.7475 - val_accuracy: 0.8000\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 2s 45ms/step - loss: 0.5532 - accuracy: 0.8042 - val_loss: 0.7476 - val_accuracy: 0.8000\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5317 - accuracy: 0.8050 - val_loss: 0.7474 - val_accuracy: 0.8000\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.4930 - accuracy: 0.8275 - val_loss: 0.7478 - val_accuracy: 0.8000\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 2s 45ms/step - loss: 0.5314 - accuracy: 0.8075 - val_loss: 0.7476 - val_accuracy: 0.8000\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 2s 43ms/step - loss: 0.5315 - accuracy: 0.8100 - val_loss: 0.7477 - val_accuracy: 0.8000\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5161 - accuracy: 0.7975 - val_loss: 0.7482 - val_accuracy: 0.8000\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5451 - accuracy: 0.8058 - val_loss: 0.7484 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17773b890>"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit_generator(generator=train_generator,epochs=100, validation_data=(xValid /255, yValid), callbacks=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 2s 44ms/step - loss: 0.5206 - accuracy: 0.8242 - val_loss: 0.7482 - val_accuracy: 0.8000\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.5441 - accuracy: 0.8108 - val_loss: 0.7487 - val_accuracy: 0.8000\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5526 - accuracy: 0.8000 - val_loss: 0.7485 - val_accuracy: 0.8000\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.5348 - accuracy: 0.8017 - val_loss: 0.7481 - val_accuracy: 0.8000\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.5068 - accuracy: 0.8192 - val_loss: 0.7483 - val_accuracy: 0.8000\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5073 - accuracy: 0.8133 - val_loss: 0.7482 - val_accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 2s 43ms/step - loss: 0.5540 - accuracy: 0.8175 - val_loss: 0.7480 - val_accuracy: 0.8000\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.5188 - accuracy: 0.8125 - val_loss: 0.7475 - val_accuracy: 0.8000\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 2s 47ms/step - loss: 0.5446 - accuracy: 0.8033 - val_loss: 0.7477 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 2s 43ms/step - loss: 0.5384 - accuracy: 0.8033 - val_loss: 0.7482 - val_accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5276 - accuracy: 0.8050 - val_loss: 0.7485 - val_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5047 - accuracy: 0.8208 - val_loss: 0.7484 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.5289 - accuracy: 0.8092 - val_loss: 0.7484 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5416 - accuracy: 0.8117 - val_loss: 0.7482 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5486 - accuracy: 0.8100 - val_loss: 0.7480 - val_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5168 - accuracy: 0.8092 - val_loss: 0.7483 - val_accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 2s 45ms/step - loss: 0.5406 - accuracy: 0.8100 - val_loss: 0.7482 - val_accuracy: 0.7983\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 2s 44ms/step - loss: 0.5263 - accuracy: 0.8242 - val_loss: 0.7481 - val_accuracy: 0.7983\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5298 - accuracy: 0.8250 - val_loss: 0.7480 - val_accuracy: 0.7983\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5321 - accuracy: 0.8075 - val_loss: 0.7479 - val_accuracy: 0.7967\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.5240 - accuracy: 0.8025 - val_loss: 0.7476 - val_accuracy: 0.7967\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 2s 43ms/step - loss: 0.5321 - accuracy: 0.8142 - val_loss: 0.7472 - val_accuracy: 0.7983\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.4991 - accuracy: 0.8275 - val_loss: 0.7475 - val_accuracy: 0.7967\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.5606 - accuracy: 0.8033 - val_loss: 0.7473 - val_accuracy: 0.7983\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.4993 - accuracy: 0.8150 - val_loss: 0.7469 - val_accuracy: 0.7983\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 2s 44ms/step - loss: 0.5607 - accuracy: 0.8000 - val_loss: 0.7467 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5349 - accuracy: 0.8008 - val_loss: 0.7467 - val_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.5577 - accuracy: 0.8033 - val_loss: 0.7469 - val_accuracy: 0.8017\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.5137 - accuracy: 0.8142 - val_loss: 0.7470 - val_accuracy: 0.8017\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5091 - accuracy: 0.8050 - val_loss: 0.7468 - val_accuracy: 0.8017\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5063 - accuracy: 0.8108 - val_loss: 0.7471 - val_accuracy: 0.8017\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5408 - accuracy: 0.8108 - val_loss: 0.7469 - val_accuracy: 0.8017\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 2s 44ms/step - loss: 0.5110 - accuracy: 0.8225 - val_loss: 0.7472 - val_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5305 - accuracy: 0.8125 - val_loss: 0.7473 - val_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 2s 48ms/step - loss: 0.5166 - accuracy: 0.8133 - val_loss: 0.7469 - val_accuracy: 0.8017\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 2s 45ms/step - loss: 0.4972 - accuracy: 0.8233 - val_loss: 0.7471 - val_accuracy: 0.8017\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 2s 49ms/step - loss: 0.5447 - accuracy: 0.8075 - val_loss: 0.7469 - val_accuracy: 0.8017\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 2s 44ms/step - loss: 0.5294 - accuracy: 0.8083 - val_loss: 0.7468 - val_accuracy: 0.8000\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 2s 43ms/step - loss: 0.5156 - accuracy: 0.8150 - val_loss: 0.7473 - val_accuracy: 0.7983\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5427 - accuracy: 0.8033 - val_loss: 0.7478 - val_accuracy: 0.8000\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5200 - accuracy: 0.8125 - val_loss: 0.7476 - val_accuracy: 0.8017\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.4992 - accuracy: 0.8300 - val_loss: 0.7474 - val_accuracy: 0.7983\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 1s 39ms/step - loss: 0.5399 - accuracy: 0.7975 - val_loss: 0.7473 - val_accuracy: 0.7983\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5216 - accuracy: 0.8258 - val_loss: 0.7475 - val_accuracy: 0.7983\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5079 - accuracy: 0.8275 - val_loss: 0.7473 - val_accuracy: 0.7967\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.5117 - accuracy: 0.8250 - val_loss: 0.7471 - val_accuracy: 0.7967\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5086 - accuracy: 0.8075 - val_loss: 0.7471 - val_accuracy: 0.7967\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5463 - accuracy: 0.8008 - val_loss: 0.7470 - val_accuracy: 0.7983\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5452 - accuracy: 0.7942 - val_loss: 0.7467 - val_accuracy: 0.7983\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5458 - accuracy: 0.7950 - val_loss: 0.7464 - val_accuracy: 0.8000\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5525 - accuracy: 0.7975 - val_loss: 0.7463 - val_accuracy: 0.8000\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5164 - accuracy: 0.8233 - val_loss: 0.7468 - val_accuracy: 0.8000\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 2s 39ms/step - loss: 0.5357 - accuracy: 0.8017 - val_loss: 0.7465 - val_accuracy: 0.8000\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5261 - accuracy: 0.8167 - val_loss: 0.7464 - val_accuracy: 0.8000\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5266 - accuracy: 0.8208 - val_loss: 0.7463 - val_accuracy: 0.8000\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5321 - accuracy: 0.8167 - val_loss: 0.7459 - val_accuracy: 0.8000\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.4986 - accuracy: 0.8233 - val_loss: 0.7458 - val_accuracy: 0.8000\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5108 - accuracy: 0.8092 - val_loss: 0.7459 - val_accuracy: 0.8000\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5270 - accuracy: 0.8100 - val_loss: 0.7459 - val_accuracy: 0.8000\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5075 - accuracy: 0.8175 - val_loss: 0.7462 - val_accuracy: 0.8000\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.4972 - accuracy: 0.8067 - val_loss: 0.7465 - val_accuracy: 0.8000\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5228 - accuracy: 0.8067 - val_loss: 0.7465 - val_accuracy: 0.8017\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.4861 - accuracy: 0.8258 - val_loss: 0.7463 - val_accuracy: 0.8000\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5023 - accuracy: 0.8267 - val_loss: 0.7464 - val_accuracy: 0.8000\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5403 - accuracy: 0.8125 - val_loss: 0.7462 - val_accuracy: 0.8000\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5501 - accuracy: 0.7983 - val_loss: 0.7465 - val_accuracy: 0.8000\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.5243 - accuracy: 0.8133 - val_loss: 0.7468 - val_accuracy: 0.8000\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 2s 45ms/step - loss: 0.4799 - accuracy: 0.8308 - val_loss: 0.7466 - val_accuracy: 0.8017\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5139 - accuracy: 0.8208 - val_loss: 0.7462 - val_accuracy: 0.8017\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 2s 43ms/step - loss: 0.5364 - accuracy: 0.8158 - val_loss: 0.7458 - val_accuracy: 0.8017\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5106 - accuracy: 0.8267 - val_loss: 0.7452 - val_accuracy: 0.8000\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5339 - accuracy: 0.8225 - val_loss: 0.7446 - val_accuracy: 0.7983\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5150 - accuracy: 0.8083 - val_loss: 0.7441 - val_accuracy: 0.7983\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5193 - accuracy: 0.8192 - val_loss: 0.7442 - val_accuracy: 0.7950\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5344 - accuracy: 0.8050 - val_loss: 0.7437 - val_accuracy: 0.7950\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 2s 44ms/step - loss: 0.5311 - accuracy: 0.8217 - val_loss: 0.7436 - val_accuracy: 0.7967\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5410 - accuracy: 0.8042 - val_loss: 0.7438 - val_accuracy: 0.7967\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5642 - accuracy: 0.7967 - val_loss: 0.7434 - val_accuracy: 0.7967\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5234 - accuracy: 0.8142 - val_loss: 0.7431 - val_accuracy: 0.7950\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5005 - accuracy: 0.8125 - val_loss: 0.7431 - val_accuracy: 0.7967\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.4802 - accuracy: 0.8317 - val_loss: 0.7429 - val_accuracy: 0.7983\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.4869 - accuracy: 0.8042 - val_loss: 0.7427 - val_accuracy: 0.7983\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5103 - accuracy: 0.8217 - val_loss: 0.7432 - val_accuracy: 0.7933\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.4861 - accuracy: 0.8333 - val_loss: 0.7431 - val_accuracy: 0.7967\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.4837 - accuracy: 0.8342 - val_loss: 0.7431 - val_accuracy: 0.7983\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5183 - accuracy: 0.8042 - val_loss: 0.7435 - val_accuracy: 0.7967\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5196 - accuracy: 0.8058 - val_loss: 0.7435 - val_accuracy: 0.7967\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.5040 - accuracy: 0.8208 - val_loss: 0.7437 - val_accuracy: 0.7950\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5461 - accuracy: 0.8025 - val_loss: 0.7434 - val_accuracy: 0.7967\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5314 - accuracy: 0.8067 - val_loss: 0.7436 - val_accuracy: 0.7967\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 0.5213 - accuracy: 0.8208 - val_loss: 0.7438 - val_accuracy: 0.7967\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.4976 - accuracy: 0.8242 - val_loss: 0.7442 - val_accuracy: 0.7967\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 2s 43ms/step - loss: 0.5236 - accuracy: 0.8125 - val_loss: 0.7440 - val_accuracy: 0.7967\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5236 - accuracy: 0.8192 - val_loss: 0.7439 - val_accuracy: 0.7967\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 2s 43ms/step - loss: 0.5334 - accuracy: 0.8167 - val_loss: 0.7429 - val_accuracy: 0.7967\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5126 - accuracy: 0.8083 - val_loss: 0.7431 - val_accuracy: 0.7950\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.5409 - accuracy: 0.8142 - val_loss: 0.7434 - val_accuracy: 0.7950\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.4943 - accuracy: 0.8250 - val_loss: 0.7438 - val_accuracy: 0.7950\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 2s 41ms/step - loss: 0.5195 - accuracy: 0.8125 - val_loss: 0.7436 - val_accuracy: 0.7967\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 2s 42ms/step - loss: 0.5124 - accuracy: 0.8133 - val_loss: 0.7431 - val_accuracy: 0.7967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x175e655d0>"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit_generator(generator=train_generator,epochs=100, validation_data=(xValid /255, yValid), callbacks=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.trainable = True\n",
    "for (idx, l) in enumerate(m.layers):  \n",
    "\n",
    "    if idx > 0:\n",
    "        l.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 26, 26, 128)       3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 10, 10, 128)       262272    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 128)               409728    \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 679,910\n",
      "Trainable params: 679,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 2s 40ms/step - loss: 0.6724 - accuracy: 0.7583 - val_loss: 0.6507 - val_accuracy: 0.7983\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.6775 - accuracy: 0.7558 - val_loss: 0.6510 - val_accuracy: 0.7983\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.7032 - accuracy: 0.7375 - val_loss: 0.6513 - val_accuracy: 0.7983\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.6677 - accuracy: 0.7533 - val_loss: 0.6510 - val_accuracy: 0.7983\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.6757 - accuracy: 0.7542 - val_loss: 0.6511 - val_accuracy: 0.7967\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.6888 - accuracy: 0.7433 - val_loss: 0.6509 - val_accuracy: 0.7967\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 1s 37ms/step - loss: 0.6728 - accuracy: 0.7575 - val_loss: 0.6504 - val_accuracy: 0.7967\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.6621 - accuracy: 0.7633 - val_loss: 0.6503 - val_accuracy: 0.7967\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.6599 - accuracy: 0.7483 - val_loss: 0.6505 - val_accuracy: 0.7967\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.6812 - accuracy: 0.7575 - val_loss: 0.6508 - val_accuracy: 0.7950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1778c8810>"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit_generator(generator=train_generator,epochs=10, validation_data=(xValid /255, yValid), callbacks=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 2s 45ms/step - loss: 0.6221 - accuracy: 0.7808 - val_loss: 0.6763 - val_accuracy: 0.7833\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 2s 45ms/step - loss: 0.6128 - accuracy: 0.7717 - val_loss: 0.6826 - val_accuracy: 0.7767\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 2s 49ms/step - loss: 0.6177 - accuracy: 0.7808 - val_loss: 0.6904 - val_accuracy: 0.7783\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 2s 49ms/step - loss: 0.6454 - accuracy: 0.7567 - val_loss: 0.6807 - val_accuracy: 0.7817\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 2s 48ms/step - loss: 0.6240 - accuracy: 0.7733 - val_loss: 0.6773 - val_accuracy: 0.7750\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 2s 47ms/step - loss: 0.6261 - accuracy: 0.7867 - val_loss: 0.6849 - val_accuracy: 0.7817\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 2s 46ms/step - loss: 0.6161 - accuracy: 0.7825 - val_loss: 0.6808 - val_accuracy: 0.7817\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 2s 50ms/step - loss: 0.5958 - accuracy: 0.7842 - val_loss: 0.6751 - val_accuracy: 0.7850\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 2s 48ms/step - loss: 0.6180 - accuracy: 0.7842 - val_loss: 0.6705 - val_accuracy: 0.7833\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 2s 48ms/step - loss: 0.5961 - accuracy: 0.7800 - val_loss: 0.6838 - val_accuracy: 0.7867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x177774e50>"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit_generator(generator=train_generator,epochs=10, validation_data=(xValid /255, yValid), callbacks=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.compile(optimizer=keras.optimizers.Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.xception import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "xValid = keras.applications.xception.preprocess_input(xValid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1200 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import preprocess_input\n",
    "import tensorflow as tf\n",
    "\n",
    "train_datagen=tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=keras.applications.xception.preprocess_input, horizontal_flip=True, width_shift_range=0.1, zoom_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.01, rotation_range=15, fill_mode=\"constant\", validation_split=0.00)\n",
    "train_generator = train_datagen.flow_from_directory('./train1200A/classes', class_mode='categorical', target_size=(128,128), subset='training')\n",
    "#valid_generator = train_datagen.flow_from_directory('./train1200A/classes', class_mode='categorical', target_size=(128,128), subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 15s 0us/step\n"
     ]
    }
   ],
   "source": [
    "resNetModel = Sequential()\n",
    "resNetModel.add(Xception(input_shape=(128,128, 3), include_top = False, pooling = 'avg', weights = 'imagenet'))\n",
    "resNetModel.add(Dropout(0.2))\n",
    "resNetModel.add(Dense(126, activation='relu'))\n",
    "\n",
    "\n",
    "# 2nd layer as Dense for 2-class classification, i.e., dog or cat using SoftMax activation\n",
    "resNetModel.add(Dense(6, activation = 'softmax'))\n",
    "\n",
    "# Say not to train first layer (ResNet) model as it is already trained\n",
    "resNetModel.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Functional)        (None, 2048)              20861480  \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 126)               258174    \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 6)                 762       \n",
      "=================================================================\n",
      "Total params: 21,120,416\n",
      "Trainable params: 258,936\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resNetModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "resNetModel.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.9354 - accuracy: 0.6567 - val_loss: 3.8978 - val_accuracy: 0.1950\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.9232 - accuracy: 0.6600 - val_loss: 3.3918 - val_accuracy: 0.1700\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.9424 - accuracy: 0.6467"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-301-eed762d2981e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresNetModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxValid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myValid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1134\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TraceContext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True)\n",
    "\n",
    "resNetModel.fit_generator(generator=train_generator,epochs=100,validation_data=(xValid, yValid), callbacks=[callback])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Category\n",
       "Id          \n",
       "0          2\n",
       "1          2\n",
       "2          4\n",
       "3          0\n",
       "4          1\n",
       "5          4\n",
       "6          2\n",
       "7          4\n",
       "8          5\n",
       "9          5\n",
       "10         4\n",
       "11         1\n",
       "12         1\n",
       "13         1\n",
       "14         4\n",
       "15         5\n",
       "16         2\n",
       "17         3\n",
       "18         0\n",
       "19         3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.to_csv('mobileNetTransferPredictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped = keras.applications.mobilenet.preprocess_input(testReshapedX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
